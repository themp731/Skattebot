{"file_contents":{"config.py":{"content":"\"\"\"Configuration settings for the ESPN Fantasy Football scraper.\"\"\"\n\n# ESPN API endpoints\nESPN_FF_BASE_URL = \"https://fantasy.espn.com/apis/v3/games/ffl\"\nLEAGUE_ENDPOINT = \"/seasons/{year}/segments/0/leagues/{league_id}\"\nBOXSCORE_ENDPOINT = \"/boxscore\"\n\n# API parameters\nDEFAULT_SEASON = 2023\nMAX_WEEK = 17\n\n# CSV output settings\nCSV_HEADERS = {\n    'matchups': [\n        'week', 'matchup_id', 'team_id', 'opponent_id',\n        'team_score', 'opponent_score', 'winner'\n    ],\n    'player_stats': [\n        'week', 'team_id', 'player_id', 'player_name',\n        'position', 'slot_position', 'points', 'projected_points'\n    ],\n    'team_stats': [\n        'week', 'team_id', 'team_name', 'points_for',\n        'points_against', 'weekly_rank'\n    ]\n}\n\n# Output file names\nOUTPUT_FILES = {\n    'matchups': 'matchups.csv',\n    'player_stats': 'player_stats.csv',\n    'team_stats': 'team_stats.csv'\n}\n","path":null,"size_bytes":895,"size_tokens":null},"csv_generator.py":{"content":"\"\"\"Generate CSV files from processed fantasy football data.\"\"\"\nimport pandas as pd\nfrom typing import Dict\nimport os\nimport logging\n\nclass CSVGenerator:\n    def __init__(self, output_dir: str = \".\"):\n        self.output_dir = output_dir\n        self._ensure_output_dir()\n\n    def _ensure_output_dir(self):\n        \"\"\"Ensure output directory exists.\"\"\"\n        try:\n            if not os.path.exists(self.output_dir):\n                os.makedirs(self.output_dir)\n        except OSError as e:\n            logging.error(f\"Failed to create output directory: {e}\")\n            raise\n\n    def save_dataframe(self, df: pd.DataFrame, filename: str):\n        \"\"\"Save DataFrame to CSV file.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            df.to_csv(output_path, index=False)\n            logging.info(f\"Successfully saved {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to save {filename}: {e}\")\n            raise\n\n    def append_to_csv(self, df: pd.DataFrame, filename: str):\n        \"\"\"Append DataFrame to existing CSV file or create new one.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            \n            if os.path.exists(output_path):\n                df.to_csv(output_path, mode='a', header=False, index=False)\n            else:\n                df.to_csv(output_path, index=False)\n                \n            logging.info(f\"Successfully appended to {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to append to {filename}: {e}\")\n            raise\n","path":null,"size_bytes":1593,"size_tokens":null},"espn_ff_scraper.py":{"content":"\"\"\"Main script for ESPN Fantasy Football data scraping.\"\"\"\nimport argparse\nimport logging\nfrom datetime import datetime\nimport sys\nfrom typing import Optional\n\nfrom espn_api import ESPNFantasyAPI\nfrom data_processor import DataProcessor\nfrom csv_generator import CSVGenerator\nfrom config import DEFAULT_SEASON, MAX_WEEK, OUTPUT_FILES\n\ndef setup_logging():\n    \"\"\"Configure logging settings.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n\ndef parse_arguments():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='ESPN Fantasy Football Data Scraper')\n    parser.add_argument('--league_id', type=int, required=True,\n                      help='ESPN Fantasy Football League ID')\n    parser.add_argument('--season', type=int, default=DEFAULT_SEASON,\n                      help=f'Season year (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int,\n                      help=f'Specific week to scrape (default: all weeks)')\n    parser.add_argument('--output', type=str, default='.',\n                      help='Output directory for CSV files')\n    return parser.parse_args()\n\ndef validate_arguments(args) -> bool:\n    \"\"\"Validate command line arguments.\"\"\"\n    if args.season < 2010 or args.season > datetime.now().year:\n        logging.error(f\"Invalid season year: {args.season}\")\n        return False\n    \n    if args.week and (args.week < 1 or args.week > MAX_WEEK):\n        logging.error(f\"Invalid week number: {args.week}\")\n        return False\n        \n    return True\n\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    setup_logging()\n    args = parse_arguments()\n    \n    if not validate_arguments(args):\n        sys.exit(1)\n\n    # Initialize components\n    api = ESPNFantasyAPI(args.league_id, args.season)\n    csv_generator = CSVGenerator(args.output)\n\n    # Validate league\n    if not api.validate_league():\n        logging.error(f\"Invalid or inaccessible league ID: {args.league_id}\")\n        sys.exit(1)\n\n    # Get league data\n    league_data = api.get_league_data()\n    if not league_data:\n        logging.error(\"Failed to fetch league data\")\n        sys.exit(1)\n\n    data_processor = DataProcessor(league_data)\n    \n    # Determine weeks to process\n    weeks = [args.week] if args.week else range(1, MAX_WEEK + 1)\n    \n    for week in weeks:\n        logging.info(f\"Processing week {week}...\")\n        \n        # Fetch boxscore data\n        boxscore_data = api.get_boxscore(week)\n        if not boxscore_data:\n            logging.warning(f\"Skipping week {week} - no data available\")\n            continue\n\n        try:\n            # Process data\n            matchups_df = data_processor.process_matchups(boxscore_data, week)\n            player_stats_df = data_processor.process_player_stats(boxscore_data, week)\n            team_stats_df = data_processor.process_team_stats(boxscore_data, week)\n\n            # Save to CSV\n            csv_generator.append_to_csv(matchups_df, OUTPUT_FILES['matchups'])\n            csv_generator.append_to_csv(player_stats_df, OUTPUT_FILES['player_stats'])\n            csv_generator.append_to_csv(team_stats_df, OUTPUT_FILES['team_stats'])\n            \n            logging.info(f\"Successfully processed week {week}\")\n            \n        except Exception as e:\n            logging.error(f\"Error processing week {week}: {e}\")\n            continue\n\n    logging.info(\"Data scraping completed successfully\")\n\nif __name__ == \"__main__\":\n    main()\n","path":null,"size_bytes":3590,"size_tokens":null},"espn_api.py":{"content":"\"\"\"ESPN Fantasy Football API interaction module.\"\"\"\nimport requests\nfrom typing import Dict, Any, Optional\nimport logging\n\nclass ESPNFantasyAPI:\n    def __init__(self, league_id: int, season: int):\n        self.league_id = league_id\n        self.season = season\n        self.base_url = \"https://fantasy.espn.com/apis/v3/games/ffl\"\n        \n    def get_league_data(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch league data from ESPN API.\"\"\"\n        try:\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            response = requests.get(url)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch league data: {e}\")\n            return None\n\n    def get_boxscore(self, week: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch boxscore data for a specific week.\"\"\"\n        try:\n            params = {\n                'scoringPeriodId': week,\n                'view': ['mBoxscore', 'mMatchupScore']\n            }\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}/matchups\"\n            response = requests.get(url, params=params)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch boxscore for week {week}: {e}\")\n            return None\n\n    def validate_league(self) -> bool:\n        \"\"\"Validate if the league ID exists and is accessible.\"\"\"\n        try:\n            league_data = self.get_league_data()\n            return league_data is not None and 'id' in league_data\n        except Exception:\n            return False\n","path":null,"size_bytes":1763,"size_tokens":null},"README.md":{"content":"# ESPN Fantasy Football Scraper & Analyzer\n\n## Overview\nA comprehensive ESPN Fantasy Football data scraper and analysis tool that downloads historical league data, generates advanced statistical visualizations, and sends weekly email recaps with AI-generated commentary.\n\n**Current Status**: Fully functional with 2025 season data (weeks 1-14 processed)\n\n## Features\n- **Data Scraping**: Pulls matchups, player stats, and team stats from ESPN's API\n- **Power Rankings**: Custom ranking system using Real Wins, Top6 Wins, and MVP-W\n- **WAX (Wins Above Expectation)**: Luck analysis showing who's running hot/cold\n- **Visualizations**: 9 charts including power rankings, weekly trends, and heatmaps\n- **AI Commentary**: Personalized, snarky weekly recaps for each team using OpenAI\n- **SkatteBot**: Your frat bro email host who summarizes the week's action\n- **PDF Reports**: Professional PDF with embedded charts\n- **Email Delivery**: Sends weekly results + PDF report to your inbox\n\n## Required Secrets\n\nAdd these under the **Secrets** tab (lock icon in the sidebar):\n\n| Key | Required | Purpose |\n| --- | --- | --- |\n| `ESPN_S2` | Private leagues only | ESPN auth cookie (long string) |\n| `SWID` | Private leagues only | ESPN auth cookie with braces |\n| `LEAGUE_ID` | Yes | Your ESPN league ID number |\n| `YEARS` | Yes | Season year (e.g., `2025`) |\n| `EMAIL_FROM` | For email | Your sending email address |\n| `EMAIL_TO` | For email | Recipient email(s), comma-separated |\n| `SMTP_HOST` | For email | SMTP server (e.g., `smtp.gmail.com`) |\n| `SMTP_PORT` | For email | Usually `587` |\n| `SMTP_USERNAME` | For email | Your email login |\n| `SMTP_PASSWORD` | For email | Your email password or app password |\n\n**How to capture ESPN cookies:**\n1. Log in to https://fantasy.espn.com and load your league page.\n2. Open browser dev tools (`F12`) -> Application/Storage tab.\n3. Expand **Cookies -> https://fantasy.espn.com**.\n4. Copy the values for `espn_s2` and `SWID` (keep the braces).\n5. Store them as `ESPN_S2` and `SWID` secrets (never commit these values).\n\nThe AI commentary uses Replit's built-in OpenAI integration - no additional API keys needed.\n\n## How to Run\n\n### Using the Run Button\nClick the **Run** button to execute the full pipeline:\n1. Scrapes ESPN data into `data/latest/`\n2. Generates reports and charts in `reports/latest/`\n3. Archives everything under `archive/<timestamp>/`\n4. Sends email with week results, PDF report, and CSV summary\n\n### Using the Shell\nFor manual runs or testing:\n```bash\npython -m src.automation.runner --league-id YOUR_LEAGUE_ID --years 2025 --verbose\n```\n\n## Setting Up Automatic Weekly Runs\n\nTo have this run automatically every week (like every Tuesday morning):\n\n1. Click **Deploy** in the top menu\n2. Choose **Scheduled** deployment type\n3. Set the command: `python -m src.automation.runner --league-id YOUR_LEAGUE_ID --years 2025`\n4. Pick your schedule (e.g., \"Every Tuesday at 8:00 AM\")\n5. Copy your secrets to the deployment environment\n6. Click **Deploy**\n\nThe scheduled deployment will automatically run the pipeline at your chosen time and send the email recap.\n\n## What the Email Contains\n\n**In the email body:**\n- SkatteBot's frat-bro summary of the week's action\n- Week number\n- This week's 5 matchup results (winner, loser, scores)\n\n**Attached:**\n- PDF report with power rankings, charts, and AI commentary for each team\n- CSV summary of all team stats\n\n## Output Files\n\nAll CSVs include a `season` column so you can combine multiple years safely.\n- `matchups.csv`: week-by-week matchups including opponent, score, and result.\n- `player_stats.csv`: per-player scoring with slot/position labels.\n- `team_stats.csv`: team totals plus advanced metrics (weekly rank, Top6 wins, MVP-W, WAX inputs).\n- `team_summary.csv`: rollup used for power rankings and newsletter narrative.\n\n## Power Rankings & Visualizations\n\nThe analysis produces the following charts on each run:\n1. `power_rankings.png` - leaderboard sorted by power score\n2. `power_breakdown.png` - stacked bars of Real Wins, Top6 Wins, MVP-W\n3. `power_rankings_evolution.png` - line chart for weekly ranking shifts\n4. `wax_leaderboard.png` - Wins Above Expectation comparison\n5. `wins_vs_expected.png` - scatter of real vs expected wins\n6. `total_points.png` - season-long points for each team\n7. `weekly_performance.png` - trends of weekly scoring\n8. `weekly_rank_heatmap.png` - heatmap of weekly ranks\n9. `consistency.png` - variation in scoring week over week\n10. `power_rankings_analysis.md` - narrative report with snark + embedded charts\n\n## Troubleshooting\n\n- **403 errors**: ESPN cookies (`ESPN_S2`/`SWID`) are missing or expired. Get fresh ones from your browser.\n- **No email sent**: Check that all email settings are configured in Secrets.\n- **Missing data**: The runner clears `data/latest/` each run. Historical data is in `archive/`.\n- **No charts**: Verify `team_stats.csv` exists in `data/latest/` before running the analysis step.\n\n## Key Metrics\n\n- **Power Score** = (Real Wins x 2) + Top6 Wins + MVP-W\n- **MVP-W** = Theoretical wins if you played every team each week\n- **WAX** = Real Wins - MVP-W (positive = lucky, negative = unlucky)\n\n## Project Structure\n```\nsrc/\n├── common/\n│   ├── config.py              - shared constants, defaults, CSV names\n│   └── position_mapping.py    - slot/position maps for ESPN IDs\n├── scraper/\n│   ├── espn_ff_scraper.py     - CLI + scrape_league helper\n│   ├── espn_api.py            - ESPN HTTP client\n│   ├── data_processor.py      - dataframe builders\n│   └── csv_generator.py       - type-safe CSV writer\n├── analysis/\n│   └── team_analysis.py       - power rankings, charts, AI commentary\n└── automation/\n    └── runner.py              - scrape -> analyze -> archive -> email\n\ndata/latest/                   - Most recent scraped data\nreports/latest/                - Most recent generated reports\narchive/                       - Historical runs by timestamp\n```\n\n## Architecture Flowchart\n\n```mermaid\nflowchart TD\n   subgraph Common\n      C1[common/config.py]\n      C2[common/position_mapping.py]\n   end\n   subgraph Scraper\n      S1[espn_ff_scraper.py\\nCLI + orchestration]\n      S2[espn_api.py\\nESPN HTTP client]\n      S3[data_processor.py\\nBuild DataFrames]\n      S4[csv_generator.py\\nPersist typed CSVs]\n   end\n   subgraph Analysis\n      A1[team_analysis.py\\nRankings + visuals + markdown]\n   end\n   subgraph Automation\n      R1[automation/runner.py\\nPipeline controller]\n   end\n   R1 --> S1\n   S1 --> S2\n   S1 --> S3\n   S3 --> S4\n   S4 -->|CSVs| A1\n   R1 --> A1\n   C1 --> S1\n   C1 --> S3\n   C1 --> A1\n   C2 --> S3\n   A1 -->|Reports & Charts| R1\n```\n\n## Privacy & Security\n- Never commit secrets; store them in Replit's secret manager.\n- ESPN cookies expire periodically - treat them like passwords and rotate when scraping fails.\n- Archives may contain sensitive matchup data; share them carefully.\n","path":null,"size_bytes":6962,"size_tokens":null},"data_processor.py":{"content":"\"\"\"Process and transform ESPN Fantasy Football data.\"\"\"\nimport pandas as pd\nfrom typing import Dict, List, Any\nimport logging\n\nclass DataProcessor:\n    def __init__(self, league_data: Dict[str, Any]):\n        self.league_data = league_data\n        self.teams_map = self._create_teams_map()\n\n    def _create_teams_map(self) -> Dict[int, str]:\n        \"\"\"Create a mapping of team IDs to team names.\"\"\"\n        teams_map = {}\n        try:\n            for team in self.league_data.get('teams', []):\n                teams_map[team['id']] = team['name']\n        except KeyError as e:\n            logging.error(f\"Error creating teams map: {e}\")\n        return teams_map\n\n    def process_matchups(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process matchup data into a DataFrame.\"\"\"\n        matchups = []\n        \n        try:\n            for matchup in boxscore_data.get('schedule', []):\n                home_team_id = matchup['home']['teamId']\n                away_team_id = matchup['away']['teamId']\n                home_score = matchup['home']['totalPoints']\n                away_score = matchup['away']['totalPoints']\n                \n                matchups.extend([\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': home_team_id,\n                        'opponent_id': away_team_id,\n                        'team_score': home_score,\n                        'opponent_score': away_score,\n                        'winner': home_score > away_score\n                    },\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': away_team_id,\n                        'opponent_id': home_team_id,\n                        'team_score': away_score,\n                        'opponent_score': home_score,\n                        'winner': away_score > home_score\n                    }\n                ])\n        except KeyError as e:\n            logging.error(f\"Error processing matchups: {e}\")\n            \n        return pd.DataFrame(matchups)\n\n    def process_player_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process player statistics into a DataFrame.\"\"\"\n        player_stats = []\n        \n        try:\n            for team in boxscore_data.get('teams', []):\n                team_id = team['id']\n                \n                for player in team.get('roster', {}).get('entries', []):\n                    player_stats.append({\n                        'week': week,\n                        'team_id': team_id,\n                        'player_id': player['playerId'],\n                        'player_name': player['playerPoolEntry']['player']['fullName'],\n                        'position': player['playerPoolEntry']['player']['defaultPositionId'],\n                        'slot_position': player['lineupSlotId'],\n                        'points': player['playerPoolEntry']['appliedStatTotal'],\n                        'projected_points': player['playerPoolEntry'].get('projectedPointTotal', 0)\n                    })\n        except KeyError as e:\n            logging.error(f\"Error processing player stats: {e}\")\n            \n        return pd.DataFrame(player_stats)\n\n    def process_team_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process team statistics into a DataFrame.\"\"\"\n        team_stats = []\n        \n        try:\n            teams_data = boxscore_data.get('teams', [])\n            sorted_teams = sorted(teams_data, key=lambda x: x['points'], reverse=True)\n            \n            for rank, team in enumerate(sorted_teams, 1):\n                team_stats.append({\n                    'week': week,\n                    'team_id': team['id'],\n                    'team_name': self.teams_map.get(team['id'], f\"Team {team['id']}\"),\n                    'points_for': team['points'],\n                    'points_against': team['pointsAgainst'],\n                    'weekly_rank': rank\n                })\n        except KeyError as e:\n            logging.error(f\"Error processing team stats: {e}\")\n            \n        return pd.DataFrame(team_stats)\n","path":null,"size_bytes":4249,"size_tokens":null},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"markdown>=3.10\",\n    \"matplotlib>=3.10.7\",\n    \"numpy>=2.2.2\",\n    \"openai>=2.9.0\",\n    \"pandas>=2.2.3\",\n    \"requests>=2.32.3\",\n    \"seaborn>=0.13.2\",\n    \"weasyprint>=67.0\",\n]\n","path":null,"size_bytes":325,"size_tokens":null},"src/common/__init__.py":{"content":"\"\"\"Common utilities for Skattebot.\"\"\"\n","path":null,"size_bytes":38,"size_tokens":null},"src/automation/__init__.py":{"content":"\"\"\"Automation orchestration for Skattebot.\"\"\"\n","path":null,"size_bytes":46,"size_tokens":null},"src/automation/runner.py":{"content":"\"\"\"Automation runner for scheduled ESPN Fantasy Football reporting.\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport mimetypes\nimport os\nimport shutil\nimport smtplib\nfrom datetime import datetime\nfrom email.message import EmailMessage\nfrom pathlib import Path\nfrom typing import List, Sequence\n\nimport markdown\nimport pandas as pd\nfrom openai import OpenAI\nfrom weasyprint import HTML, CSS\n\nfrom src.analysis.team_analysis import run_analysis\nfrom src.common.config import DEFAULT_SEASON\nfrom src.scraper.espn_ff_scraper import scrape_league\n\nBASE_DIR = Path(__file__).resolve().parents[2]\nDATA_LATEST_DIR = BASE_DIR / 'data' / 'latest'\nREPORT_LATEST_DIR = BASE_DIR / 'reports' / 'latest'\nARCHIVE_ROOT = BASE_DIR / 'archive'\n\n\ndef configure_logging(verbose: bool = False) -> None:\n    level = logging.DEBUG if verbose else logging.INFO\n    logging.basicConfig(\n        level=level,\n        format='%(asctime)s - %(levelname)s - %(message)s'\n    )\n\n\ndef reset_directory(path: Path) -> Path:\n    if path.exists():\n        shutil.rmtree(path)\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n\n\ndef archive_run(data_dir: Path, report_dir: Path) -> Path:\n    ARCHIVE_ROOT.mkdir(parents=True, exist_ok=True)\n    timestamp = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')\n    run_dir = ARCHIVE_ROOT / timestamp\n    shutil.copytree(data_dir, run_dir / 'data')\n    shutil.copytree(report_dir, run_dir / 'reports')\n    logging.info(\"Archived artifacts to %s\", run_dir)\n    return run_dir\n\n\ndef parse_recipients(raw: str | None) -> List[str]:\n    if not raw:\n        return []\n    return [item.strip() for item in raw.split(',') if item.strip()]\n\n\ndef generate_skattebot_intro(week_num: int, weekly_results: str) -> str:\n    \"\"\"Generate SkatteBot's frat-bro style intro for the email.\"\"\"\n    try:\n        client = OpenAI(\n            api_key=os.getenv(\"AI_INTEGRATIONS_OPENAI_API_KEY\"),\n            base_url=os.getenv(\"AI_INTEGRATIONS_OPENAI_BASE_URL\")\n        )\n        \n        prompt = f\"\"\"You are SkatteBot, a fantasy football commentator who is a frat bro that loves beer and tacos. \nWrite a 2-3 sentence intro for this week's fantasy football recap email. \nIntroduce yourself as \"SkatteBot\" at the start.\nBe funny, use bro-speak, and reference beer/tacos naturally.\nSummarize the most exciting parts of this week's matchups.\n\nWeek {week_num} Results:\n{weekly_results}\n\nKeep it short, fun, and hype up the action!\"\"\"\n\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=150,\n            temperature=0.9\n        )\n        \n        return response.choices[0].message.content.strip()\n        \n    except Exception as e:\n        logging.warning(f\"Failed to generate SkatteBot intro: {e}\")\n        return \"Yo bros, it's SkatteBot here with your weekly fantasy recap! Let's see who crushed it and who needs more tacos.\"\n\n\ndef format_weekly_results(matchups_path: Path) -> tuple[int, str]:\n    \"\"\"Format the most recent week's actual head-to-head matchup results for email body.\n    \n    Returns:\n        Tuple of (week_number, formatted_results_string)\n    \"\"\"\n    if not matchups_path.exists():\n        return 0, \"No matchup data available.\"\n    \n    df = pd.read_csv(matchups_path)\n    latest_week = int(df['week'].max())\n    week_df = df[df['week'] == latest_week].copy()\n    \n    actual_matchup_ids = sorted(week_df['matchup_id'].unique())[-5:]\n    real_matchups = week_df[week_df['matchup_id'].isin(actual_matchup_ids)]\n    \n    matchups_seen = set()\n    results_lines = []\n    \n    for _, row in real_matchups.iterrows():\n        matchup_id = row['matchup_id']\n        if matchup_id in matchups_seen:\n            continue\n        matchups_seen.add(matchup_id)\n        \n        team1 = row['team_name']\n        team2 = row['opponent_name']\n        score1 = row['team_score']\n        score2 = row['opponent_score']\n        \n        if row['winner']:\n            winner = team1\n            loser = team2\n            winner_score = score1\n            loser_score = score2\n        else:\n            winner = team2\n            loser = team1\n            winner_score = score2\n            loser_score = score1\n        \n        margin = abs(score1 - score2)\n        results_lines.append(\n            f\"  {winner} def. {loser}  ({winner_score:.2f} - {loser_score:.2f})\"\n        )\n    \n    results_text = \"\\n\".join(results_lines)\n    return latest_week, results_text\n\n\ndef generate_pdf_from_markdown(md_path: Path, output_pdf: Path) -> Path:\n    \"\"\"Convert markdown file to PDF with embedded images.\"\"\"\n    md_content = md_path.read_text()\n    \n    html_content = markdown.markdown(\n        md_content,\n        extensions=['tables', 'fenced_code', 'codehilite']\n    )\n    \n    base_path = md_path.parent.as_uri() + '/'\n    \n    styled_html = f\"\"\"\n    <!DOCTYPE html>\n    <html>\n    <head>\n        <meta charset=\"utf-8\">\n        <base href=\"{base_path}\">\n        <style>\n            body {{\n                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif;\n                line-height: 1.6;\n                max-width: 900px;\n                margin: 0 auto;\n                padding: 20px;\n                color: #333;\n            }}\n            h1 {{ color: #1a1a2e; border-bottom: 3px solid #4a90d9; padding-bottom: 10px; }}\n            h2 {{ color: #16213e; margin-top: 30px; }}\n            h3 {{ color: #0f3460; }}\n            img {{ max-width: 100%; height: auto; margin: 20px 0; border-radius: 8px; box-shadow: 0 2px 8px rgba(0,0,0,0.1); }}\n            table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n            th, td {{ border: 1px solid #ddd; padding: 10px; text-align: left; }}\n            th {{ background-color: #4a90d9; color: white; }}\n            tr:nth-child(even) {{ background-color: #f9f9f9; }}\n            code {{ background-color: #f4f4f4; padding: 2px 6px; border-radius: 4px; font-size: 0.9em; }}\n            pre {{ background-color: #2d2d2d; color: #f8f8f2; padding: 15px; border-radius: 8px; overflow-x: auto; }}\n            pre code {{ background-color: transparent; color: inherit; }}\n            hr {{ border: none; border-top: 2px solid #eee; margin: 30px 0; }}\n            blockquote {{ border-left: 4px solid #4a90d9; margin: 20px 0; padding-left: 20px; color: #666; }}\n        </style>\n    </head>\n    <body>\n        {html_content}\n    </body>\n    </html>\n    \"\"\"\n    \n    HTML(string=styled_html, base_url=str(md_path.parent)).write_pdf(output_pdf)\n    logging.info(\"Generated PDF report: %s\", output_pdf)\n    return output_pdf\n\n\ndef build_email(subject: str,\n                body: str,\n                sender: str,\n                recipients: Sequence[str],\n                attachments: Sequence[Path]) -> EmailMessage:\n    msg = EmailMessage()\n    msg['Subject'] = subject\n    msg['From'] = sender\n    msg['To'] = ', '.join(recipients)\n    msg.set_content(body)\n\n    for attachment in attachments:\n        if not attachment.exists():\n            logging.warning(\"Attachment %s not found; skipping\", attachment)\n            continue\n        mime_type, _ = mimetypes.guess_type(attachment.name)\n        maintype, subtype = (mime_type or 'application/octet-stream').split('/', 1)\n        msg.add_attachment(\n            attachment.read_bytes(),\n            maintype=maintype,\n            subtype=subtype,\n            filename=attachment.name\n        )\n    return msg\n\n\ndef send_email(message: EmailMessage,\n               host: str,\n               port: int,\n               username: str | None,\n               password: str | None,\n               use_tls: bool = True) -> None:\n    smtp = smtplib.SMTP(host, port) if use_tls else smtplib.SMTP_SSL(host, port)\n    with smtp:\n        if use_tls:\n            smtp.ehlo()\n            smtp.starttls()\n            smtp.ehlo()\n        if username and password:\n            smtp.login(username, password)\n        smtp.send_message(message)\n        logging.info(\"Sent notification email to %s\", message['To'])\n\n\ndef run(args: argparse.Namespace) -> None:\n    configure_logging(args.verbose)\n\n    logging.info(\"Preparing directories\")\n    reset_directory(DATA_LATEST_DIR)\n    reset_directory(REPORT_LATEST_DIR)\n\n    logging.info(\"Starting scraper for league %s\", args.league_id)\n    scrape_league(\n        league_id=args.league_id,\n        years=args.years,\n        week=args.week,\n        output_dir=str(DATA_LATEST_DIR)\n    )\n\n    team_stats_path = DATA_LATEST_DIR / 'team_stats.csv'\n    matchups_path = DATA_LATEST_DIR / 'matchups.csv'\n    player_stats_path = DATA_LATEST_DIR / 'player_stats.csv'\n    \n    if not team_stats_path.exists():\n        raise FileNotFoundError(f\"Expected {team_stats_path} to exist after scraping\")\n\n    logging.info(\"Running analysis step with AI commentary\")\n    artifacts = run_analysis(\n        team_stats_path,\n        REPORT_LATEST_DIR,\n        matchups_path=matchups_path,\n        player_stats_path=player_stats_path\n    )\n\n    archive_dir = archive_run(DATA_LATEST_DIR, REPORT_LATEST_DIR)\n\n    recipients = parse_recipients(args.email_to or os.getenv('EMAIL_TO'))\n    sender = args.email_from or os.getenv('EMAIL_FROM')\n\n    smtp_host = args.smtp_host or os.getenv('SMTP_HOST')\n    smtp_port = int(args.smtp_port or os.getenv('SMTP_PORT', '587'))\n    smtp_user = args.smtp_username or os.getenv('SMTP_USERNAME')\n    smtp_pass = args.smtp_password or os.getenv('SMTP_PASSWORD')\n    use_tls = not args.smtp_disable_tls\n\n    if recipients and sender and smtp_host:\n        pdf_path = REPORT_LATEST_DIR / 'power_rankings_report.pdf'\n        generate_pdf_from_markdown(artifacts['markdown'], pdf_path)\n        \n        week_num, weekly_results = format_weekly_results(matchups_path)\n        skattebot_intro = generate_skattebot_intro(week_num, weekly_results)\n        \n        subject = f\"ESPN Fantasy Recap - Week {week_num} ({datetime.utcnow():%Y-%m-%d})\"\n        body = (\n            f\"{skattebot_intro}\\n\\n\"\n            f\"{'=' * 45}\\n\"\n            f\"WEEK {week_num} RESULTS:\\n\"\n            f\"{'-' * 30}\\n\"\n            f\"{weekly_results}\\n\\n\"\n            f\"{'=' * 45}\\n\"\n            f\"See attached PDF for full power rankings, charts, and AI commentary.\"\n        )\n        attachments = [pdf_path, artifacts['summary_csv']]\n        message = build_email(subject, body, sender, recipients, attachments)\n        send_email(message, smtp_host, smtp_port, smtp_user, smtp_pass, use_tls=use_tls)\n    else:\n        logging.info(\"Email configuration incomplete; skipping notification\")\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description='Automate scraping, analysis, archiving, and notifications.')\n    parser.add_argument('--league-id', type=int, required=True, help='ESPN Fantasy Football League ID')\n    parser.add_argument('--years', type=int, nargs='+', default=[DEFAULT_SEASON],\n                        help=f'Season year(s) to scrape (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int, help='Specific week to scrape (default: all weeks)')\n    parser.add_argument('--email-to', help='Comma-separated recipient list (overrides EMAIL_TO env)')\n    parser.add_argument('--email-from', help='Sender email (overrides EMAIL_FROM env)')\n    parser.add_argument('--smtp-host', help='SMTP host (overrides SMTP_HOST env)')\n    parser.add_argument('--smtp-port', help='SMTP port (default/env: 587)')\n    parser.add_argument('--smtp-username', help='SMTP username (overrides SMTP_USERNAME env)')\n    parser.add_argument('--smtp-password', help='SMTP password (overrides SMTP_PASSWORD env)')\n    parser.add_argument('--smtp-disable-tls', action='store_true', help='Use SSL instead of STARTTLS')\n    parser.add_argument('--verbose', action='store_true', help='Enable debug logging')\n    return parser.parse_args()\n\n\nif __name__ == '__main__':\n    run(parse_args())\n","path":null,"size_bytes":11922,"size_tokens":null},"src/common/config.py":{"content":"\"\"\"Configuration settings for the ESPN Fantasy Football scraper.\"\"\"\n\n# ESPN API endpoints\nESPN_FF_BASE_URL = \"https://lm-api-reads.fantasy.espn.com/apis/v3/games/ffl\"\nLEAGUE_ENDPOINT = \"/seasons/{year}/segments/0/leagues/{league_id}\"\nBOXSCORE_ENDPOINT = \"/boxscore\"\n\n# API parameters\nDEFAULT_SEASON = 2023\nMAX_WEEK = 17\n\n# CSV output settings\nCSV_HEADERS = {\n    'matchups': [\n        'week', 'matchup_id', 'team_id', 'team_name', 'opponent_id', 'opponent_name',\n        'team_score', 'opponent_score', 'winner', 'season'\n    ],\n    'player_stats': [\n        'week', 'team_id', 'team_name', 'player_id', 'player_name',\n        'position', 'slot_position', 'points', 'projected_points', 'season'\n    ],\n    'team_stats': [\n        'week', 'team_id', 'team_name', 'points_for',\n        'points_against', 'weekly_rank', 'wins', 'top6_wins', 'mvp_w', 'season'\n    ]\n}\n\n# Output file names\nOUTPUT_FILES = {\n    'matchups': 'matchups.csv',\n    'player_stats': 'player_stats.csv',\n    'team_stats': 'team_stats.csv'\n}\n","path":null,"size_bytes":1011,"size_tokens":null},"src/scraper/espn_ff_scraper.py":{"content":"\"\"\"Main script for ESPN Fantasy Football data scraping.\"\"\"\nimport argparse\nimport logging\nimport os\nimport sys\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom src.common.config import DEFAULT_SEASON, MAX_WEEK, OUTPUT_FILES\nfrom src.scraper.csv_generator import CSVGenerator\nfrom src.scraper.data_processor import DataProcessor\nfrom src.scraper.espn_api import ESPNFantasyAPI\n\n\ndef setup_logging():\n    \"\"\"Configure logging settings.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n\n\ndef parse_arguments():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='ESPN Fantasy Football Data Scraper')\n    parser.add_argument('--league_id', type=int, required=True,\n                        help='ESPN Fantasy Football League ID')\n    parser.add_argument('--years', type=int, nargs='+', default=[DEFAULT_SEASON],\n                        help=f'Season year(s) to scrape - can specify multiple (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int,\n                        help='Specific week to scrape (default: all weeks)')\n    parser.add_argument('--output', type=str, default='.',\n                        help='Output directory for CSV files')\n    return parser.parse_args()\n\n\ndef validate_arguments(args) -> bool:\n    \"\"\"Validate command line arguments.\"\"\"\n    current_year = datetime.now().year\n    for year in args.years:\n        if year < 2010 or year > current_year:\n            logging.error(f\"Invalid season year: {year}\")\n            return False\n\n    if args.week and (args.week < 1 or args.week > MAX_WEEK):\n        logging.error(f\"Invalid week number: {args.week}\")\n        return False\n\n    return True\n\n\ndef clear_existing_csv_files(output_dir: str):\n    \"\"\"Clear existing CSV files before starting a new scrape.\"\"\"\n    csv_files = [OUTPUT_FILES['matchups'], OUTPUT_FILES['player_stats'], OUTPUT_FILES['team_stats']]\n\n    for csv_file in csv_files:\n        file_path = os.path.join(output_dir, csv_file)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n            logging.info(f\"Cleared existing file: {csv_file}\")\n\n\ndef has_week_been_played(boxscore_data: dict, requested_week: int) -> bool:\n    \"\"\"Check if a week has been played by finding matchups for that specific week.\n\n    ESPN returns all matchups for the season in the 'schedule' field.\n    We need to find matchups where matchupPeriodId == requested_week and check if they have scores.\n    \"\"\"\n    if not boxscore_data:\n        return False\n\n    schedule = boxscore_data.get('schedule', [])\n    if not schedule:\n        return False\n\n    # Find matchups for the requested week\n    week_matchups = [m for m in schedule if m.get('matchupPeriodId') == requested_week]\n\n    if not week_matchups:\n        # No matchups found for this week (week doesn't exist)\n        return False\n\n    # Check if any matchup for this week has actual scores\n    for matchup in week_matchups:\n        home_score = matchup.get('home', {}).get('totalPoints', 0)\n        away_score = matchup.get('away', {}).get('totalPoints', 0)\n\n        # If any team has scored points, the week has been played\n        if home_score > 0 or away_score > 0:\n            return True\n\n    # All matchups for this week have 0 scores\n    return False\n\n\ndef scrape_league(league_id: int, years: list[int], week: Optional[int], output_dir: str) -> None:\n    \"\"\"Scrape ESPN Fantasy Football data for the given parameters.\"\"\"\n    # Get ESPN authentication credentials from environment variables (for private leagues)\n    espn_s2 = os.getenv('ESPN_S2')\n    swid = os.getenv('SWID')\n\n    if espn_s2 and swid:\n        logging.info(\"Using ESPN authentication credentials for private league access\")\n    else:\n        logging.info(\"No authentication credentials found - accessing public league only\")\n\n    # Clear existing CSV files to start fresh\n    clear_existing_csv_files(output_dir)\n\n    csv_generator = CSVGenerator(output_dir)\n\n    # Determine weeks to process\n    weeks = [week] if week else range(1, MAX_WEEK + 1)\n\n    # Loop through each year\n    for year in years:\n        logging.info(f\"Processing season {year}...\")\n\n        # Initialize API for this year with optional authentication\n        api = ESPNFantasyAPI(league_id, year, espn_s2=espn_s2, swid=swid)\n\n        # Validate league\n        if not api.validate_league():\n            logging.error(f\"Invalid or inaccessible league ID: {league_id} for season {year}\")\n            continue\n\n        # Get league data\n        league_data = api.get_league_data()\n        if not league_data:\n            logging.error(f\"Failed to fetch league data for season {year}\")\n            continue\n\n        data_processor = DataProcessor(league_data)\n\n        # Process each week for this year\n        for week_number in weeks:\n            logging.info(f\"Processing {year} week {week_number}...\")\n\n            # Fetch boxscore data\n            boxscore_data = api.get_boxscore(week_number)\n            if not boxscore_data:\n                logging.warning(f\"Skipping {year} week {week_number} - no data available\")\n                continue\n\n            # Check if the week has been played (matchupPeriodId matches requested week)\n            if not has_week_been_played(boxscore_data, week_number):\n                logging.info(f\"Skipping {year} week {week_number} - no games played yet\")\n                continue\n\n            try:\n                # Process data\n                matchups_df = data_processor.process_matchups(boxscore_data, week_number)\n                player_stats_df = data_processor.process_player_stats(boxscore_data, week_number)\n                team_stats_df = data_processor.process_team_stats(boxscore_data, week_number)\n\n                # Add season column to track which year the data is from\n                matchups_df['season'] = year\n                player_stats_df['season'] = year\n                team_stats_df['season'] = year\n\n                # Save to CSV\n                csv_generator.append_to_csv(matchups_df, OUTPUT_FILES['matchups'])\n                csv_generator.append_to_csv(player_stats_df, OUTPUT_FILES['player_stats'])\n                csv_generator.append_to_csv(team_stats_df, OUTPUT_FILES['team_stats'])\n\n                logging.info(f\"Successfully processed {year} week {week_number}\")\n\n            except Exception as exc:\n                logging.error(f\"Error processing {year} week {week_number}: {exc}\")\n                continue\n\n    logging.info(\"Data scraping completed successfully\")\n\n\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    setup_logging()\n    args = parse_arguments()\n\n    if not validate_arguments(args):\n        sys.exit(1)\n\n    scrape_league(\n        league_id=args.league_id,\n        years=args.years,\n        week=args.week,\n        output_dir=args.output\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n","path":null,"size_bytes":6987,"size_tokens":null},"src/__init__.py":{"content":"\"\"\"Skattebot source package.\"\"\"\n","path":null,"size_bytes":32,"size_tokens":null},"src/scraper/csv_generator.py":{"content":"\"\"\"Generate CSV files from processed fantasy football data.\"\"\"\nimport os\nimport logging\nfrom typing import Dict\n\nimport pandas as pd\n\n\nclass CSVGenerator:\n    def __init__(self, output_dir: str = \".\"):\n        self.output_dir = output_dir\n        self._ensure_output_dir()\n\n    def _ensure_output_dir(self):\n        \"\"\"Ensure output directory exists.\"\"\"\n        try:\n            if not os.path.exists(self.output_dir):\n                os.makedirs(self.output_dir)\n        except OSError as e:\n            logging.error(f\"Failed to create output directory: {e}\")\n            raise\n\n    def save_dataframe(self, df: pd.DataFrame, filename: str):\n        \"\"\"Save DataFrame to CSV file.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            df.to_csv(output_path, index=False)\n            logging.info(f\"Successfully saved {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to save {filename}: {e}\")\n            raise\n\n    def append_to_csv(self, df: pd.DataFrame, filename: str):\n        \"\"\"Append DataFrame to existing CSV file or create new one.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n\n            if os.path.exists(output_path):\n                df.to_csv(output_path, mode='a', header=False, index=False)\n            else:\n                df.to_csv(output_path, index=False)\n\n            logging.info(f\"Successfully appended to {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to append to {filename}: {e}\")\n            raise\n","path":null,"size_bytes":1567,"size_tokens":null},"src/analysis/team_analysis.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nESPN Fantasy Football Team Statistics Analysis\nGenerates summary tables, markdown reports, and visualizations including WAX (Wins Above Expectation).\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport os\nfrom pathlib import Path\nfrom typing import Iterable, Optional\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom openai import OpenAI\n\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = 'white'\n\nDEFAULT_TEAM_STATS = \"team_stats.csv\"\nDEFAULT_REPORT_DIR = \".\"\nVISUALIZATIONS_SUBDIR = \"visualizations\"\n\n\ndef _ensure_dir(path: Path) -> Path:\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n\n\ndef generate_ai_commentary(\n    team_name: str,\n    matchup_data: pd.DataFrame,\n    player_data: pd.DataFrame,\n    summary_row: pd.Series\n) -> str:\n    \"\"\"Generate AI commentary for a team based on their most recent matchup and player performance.\"\"\"\n    try:\n        client = OpenAI(\n            api_key=os.getenv(\"AI_INTEGRATIONS_OPENAI_API_KEY\"),\n            base_url=os.getenv(\"AI_INTEGRATIONS_OPENAI_BASE_URL\")\n        )\n        \n        # Get most recent week's matchup for this team\n        team_matchups = matchup_data[matchup_data['team_name'] == team_name]\n        if team_matchups.empty:\n            return \"\"\n        \n        latest_week = team_matchups['week'].max()\n        latest_matchup = team_matchups[team_matchups['week'] == latest_week].iloc[0]\n        \n        # Get player stats for the most recent week\n        team_players = player_data[\n            (player_data['team_name'] == team_name) & \n            (player_data['week'] == latest_week)\n        ].sort_values('points', ascending=False)\n        \n        # Get top 5 performers\n        top_players = team_players.head(5)\n        top_players_str = \"\\n\".join([\n            f\"  - {row['player_name']} ({row['position']}): {row['points']:.1f} pts\"\n            for _, row in top_players.iterrows()\n        ])\n        \n        # Build the prompt\n        won_lost = \"won\" if latest_matchup['winner'] else \"lost\"\n        margin = abs(latest_matchup['team_score'] - latest_matchup['opponent_score'])\n        \n        prompt = f\"\"\"You are a witty fantasy football analyst writing personalized commentary for a team's weekly performance.\n\nTeam: {team_name}\nWeek {latest_week} Result: {won_lost} against {latest_matchup['opponent_name']}\nScore: {latest_matchup['team_score']:.2f} - {latest_matchup['opponent_score']:.2f} (margin: {margin:.2f})\n\nSeason Stats:\n- Power Rank: #{int(summary_row['power_rank'])}\n- Record: {int(summary_row['real_wins'])}-{int(summary_row['games_played'] - summary_row['real_wins'])}\n- Points Per Game: {summary_row['ppg']:.2f}\n- WAX (Luck Index): {summary_row['wax']:+.2f}\n\nTop Performers This Week:\n{top_players_str}\n\nWrite a brief (2-3 sentences) snarky but insightful commentary about this team's week. Be entertaining and reference specific players or matchup details. Keep it fun and engaging for a fantasy football audience.\"\"\"\n\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=200,\n            temperature=0.8\n        )\n        \n        return response.choices[0].message.content.strip()\n        \n    except Exception as e:\n        logging.warning(f\"Failed to generate AI commentary for {team_name}: {e}\")\n        return \"\"\n\n\ndef load_data(filename: str | Path = DEFAULT_TEAM_STATS) -> pd.DataFrame:\n    \"\"\"Load team stats from CSV.\"\"\"\n    return pd.read_csv(Path(filename))\n\n\ndef calculate_summary_stats(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Calculate season summary statistics including WAX.\"\"\"\n    summary = df.groupby(['team_name', 'season']).agg({\n        'wins': 'sum',\n        'mvp_w': 'sum',\n        'top6_wins': 'sum',\n        'points_for': 'sum',\n        'points_against': 'sum',\n        'weekly_rank': 'mean'\n    }).reset_index()\n\n    summary['wax'] = summary['wins'] - summary['mvp_w']\n\n    weeks_played = df.groupby(['team_name', 'season']).size().reset_index(name='games_played')\n    summary = summary.merge(weeks_played, on=['team_name', 'season'])\n    summary['ppg'] = summary['points_for'] / summary['games_played']\n    summary['papg'] = summary['points_against'] / summary['games_played']\n\n    summary = summary.rename(columns={\n        'wins': 'real_wins',\n        'weekly_rank': 'avg_weekly_rank'\n    })\n\n    summary['power_score'] = (summary['real_wins'] * 2) + summary['top6_wins'] + summary['mvp_w']\n    summary['power_rank'] = summary.groupby('season')['power_score'].rank(ascending=False, method='min').astype(int)\n\n    summary['wax'] = summary['wax'].round(2)\n    summary['ppg'] = summary['ppg'].round(2)\n    summary['papg'] = summary['papg'].round(2)\n    summary['avg_weekly_rank'] = summary['avg_weekly_rank'].round(2)\n    summary['power_score'] = summary['power_score'].round(2)\n\n    summary = summary.sort_values('wax', ascending=False)\n    return summary\n\n\ndef print_summary_table(summary: pd.DataFrame) -> None:\n    \"\"\"Print formatted summary table.\"\"\"\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ESPN FANTASY FOOTBALL TEAM SUMMARY\")\n    print(\"=\" * 100)\n    print(\"\\nPOWER RANKINGS FORMULA:\")\n    print(\"  [Power Score] = (Real Wins × 2) + (Top6 Wins × 1) + (MVP-W × 1)\")\n    print(\"  This weights actual matchup wins heavily while rewarding consistent high scoring.\")\n    print(\"\\nWINS ABOVE EXPECTATION (WAX):\")\n    print(\"  [WAX] = [Real Wins] - [MVP-W]\")\n    print(\"  MVP-W represents theoretical wins if playing all teams every week.\")\n    print(\"  Positive WAX = lucky (running hot), Negative WAX = unlucky (running cold).\")\n    print(\"=\" * 100)\n    print()\n\n    display_cols = ['team_name', 'season', 'power_rank', 'power_score', 'real_wins',\n                    'top6_wins', 'mvp_w', 'wax', 'ppg', 'games_played']\n    display_df = summary[display_cols].copy()\n    display_df.columns = ['Team', 'Season', 'Rank', 'Power', 'Wins', 'Top6',\n                          'MVP-W', 'WAX', 'PPG', 'GP']\n\n    print(display_df.to_string(index=False))\n    print(\"\\n\" + \"=\" * 100)\n    print(f\"Total Teams: {len(display_df)}\")\n    print(\"=\" * 100 + \"\\n\")\n\n\ndef _viz_colors(length: int) -> Iterable:\n    return plt.cm.get_cmap('RdYlGn')(np.linspace(0.3, 0.9, length))\n\n\ndef create_visualizations(df: pd.DataFrame, summary: pd.DataFrame, output_dir: str | Path = VISUALIZATIONS_SUBDIR) -> None:\n    \"\"\"Create comprehensive visualizations.\"\"\"\n    output_dir = _ensure_dir(Path(output_dir))\n    latest_season = df['season'].max()\n    current_summary = summary[summary['season'] == latest_season].copy()\n\n    def _save(fig, path: Path, message: str):\n        fig.tight_layout()\n        fig.savefig(path, dpi=300, bbox_inches='tight')\n        print(f\"✓ Created: {path.as_posix()} - {message}\")\n        plt.close(fig)\n\n    # Figure 0: Power Rankings\n    fig, ax = plt.subplots(figsize=(12, 9))\n    power_sorted = current_summary.sort_values('power_score', ascending=True)\n    colors_power = _viz_colors(len(power_sorted))[::-1]\n    bars = ax.barh(power_sorted['team_name'], power_sorted['power_score'],\n                   color=colors_power, alpha=0.85, edgecolor='black', linewidth=1.5)\n    ax.set_xlabel('Power Score', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Rankings - {latest_season} Season\\nFormula: (Wins × 2) + (Top6 Wins) + (MVP-W)',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar, (_, row) in zip(bars, power_sorted.iterrows()):\n        width = bar.get_width()\n        ax.text(width + 0.3, bar.get_y() + bar.get_height() / 2,\n                f'{width:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n        ax.text(0.5, bar.get_y() + bar.get_height() / 2,\n                f'#{int(row[\"power_rank\"])}', ha='left', va='center', fontweight='bold', fontsize=11,\n                color='white', bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n    _save(fig, output_dir / 'power_rankings.png', 'Overall power rankings')\n\n    # Figure 1: WAX Leaderboard\n    fig, ax = plt.subplots(figsize=(12, 8))\n    colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in current_summary['wax']]\n    bars = ax.barh(current_summary['team_name'], current_summary['wax'], color=colors, alpha=0.8)\n    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n    ax.set_xlabel('WAX (Wins Above Expectation)', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Fantasy Football Luck Index - {latest_season} Season\\nWAX = Real Wins - MVP-W',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar, val in zip(bars, current_summary['wax']):\n        label = f'{val:+.2f}'\n        x_pos = val + (0.1 if val > 0 else -0.1)\n        ha = 'left' if val > 0 else 'right'\n        ax.text(x_pos, bar.get_y() + bar.get_height() / 2, label,\n                ha=ha, va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'wax_leaderboard.png', 'Luck index (WAX) leaderboard')\n\n    # Figure 2: Real Wins vs MVP-W Scatter\n    fig, ax = plt.subplots(figsize=(10, 10))\n    scatter = ax.scatter(current_summary['mvp_w'], current_summary['real_wins'],\n                         s=200, c=current_summary['wax'], cmap='RdYlGn',\n                         alpha=0.8, edgecolors='black', linewidth=1.5)\n    min_val = min(current_summary['mvp_w'].min(), current_summary['real_wins'].min())\n    max_val = max(current_summary['mvp_w'].max(), current_summary['real_wins'].max())\n    ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, linewidth=2,\n            label='Expected (No Luck)')\n    for _, row in current_summary.iterrows():\n        ax.annotate(row['team_name'], (row['mvp_w'], row['real_wins']),\n                    xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n    ax.set_xlabel('MVP-W (Expected Wins)', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Real Wins', fontsize=12, fontweight='bold')\n    ax.set_title(f'Luck Analysis: Real Wins vs Expected Wins - {latest_season}\\nAbove Line = Lucky, Below Line = Unlucky',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3)\n    ax.legend(loc='upper left', fontsize=11)\n    cbar = plt.colorbar(scatter, ax=ax)\n    cbar.set_label('WAX', rotation=270, labelpad=20, fontweight='bold', fontsize=11)\n    _save(fig, output_dir / 'wins_vs_expected.png', 'Real wins vs expected wins')\n\n    # Figure 3: Total Points Scored\n    fig, ax = plt.subplots(figsize=(12, 8))\n    sorted_summary = current_summary.sort_values('points_for', ascending=True)\n    colors_pf = _viz_colors(len(sorted_summary))\n    bars = ax.barh(sorted_summary['team_name'], sorted_summary['points_for'],\n                   color=colors_pf, alpha=0.8)\n    ax.set_xlabel('Total Points For', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Total Points Scored - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar in bars:\n        width = bar.get_width()\n        ax.text(width - 30, bar.get_y() + bar.get_height() / 2,\n                f'{width:.1f}', ha='right', va='center', fontweight='bold', fontsize=10, color='white')\n    _save(fig, output_dir / 'total_points.png', 'Total points scored')\n\n    # Figure 4: Power Score Breakdown (Stacked Bar)\n    fig, ax = plt.subplots(figsize=(12, 9))\n    breakdown_sorted = current_summary.sort_values('power_score', ascending=True)\n    wins_component = breakdown_sorted['real_wins'] * 2\n    top6_component = breakdown_sorted['top6_wins']\n    mvp_component = breakdown_sorted['mvp_w']\n    y_pos = np.arange(len(breakdown_sorted))\n    ax.barh(y_pos, wins_component, label='Real Wins (×2)', color='#2ecc71', alpha=0.9)\n    ax.barh(y_pos, top6_component, left=wins_component, label='Top6 Wins', color='#3498db', alpha=0.9)\n    ax.barh(y_pos, mvp_component, left=wins_component + top6_component,\n            label='MVP-W', color='#9b59b6', alpha=0.9)\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(breakdown_sorted['team_name'])\n    ax.set_xlabel('Power Score Components', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Score Breakdown - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.legend(loc='lower right', fontsize=10, framealpha=0.9)\n    ax.grid(axis='x', alpha=0.3)\n    for i, (_, row) in enumerate(breakdown_sorted.iterrows()):\n        total = row['power_score']\n        ax.text(total + 0.3, i, f'{total:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'power_breakdown.png', 'Power score components')\n\n    # Figure 5: Weekly Performance Over Time\n    fig, ax = plt.subplots(figsize=(14, 8))\n    current_df = df[df['season'] == latest_season].copy()\n    for team in current_df['team_name'].unique():\n        team_data = current_df[current_df['team_name'] == team].sort_values('week')\n        ax.plot(team_data['week'], team_data['points_for'], marker='o', linewidth=2, markersize=6,\n                label=team, alpha=0.7)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Points Scored', fontsize=12, fontweight='bold')\n    ax.set_title(f'Weekly Points Scored - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3)\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n    _save(fig, output_dir / 'weekly_performance.png', 'Weekly scoring trends')\n\n    # Figure 6: Weekly Rank Heatmap\n    fig, ax = plt.subplots(figsize=(14, 10))\n    pivot_data = current_df.pivot(index='team_name', columns='week', values='weekly_rank').sort_index()\n    sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn_r', cbar_kws={'label': 'Weekly Rank'},\n                linewidths=0.5, vmin=1, vmax=12, ax=ax, center=6.5)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Weekly Rank Heatmap - {latest_season} Season\\n(1 = Best, 12 = Worst)',\n                 fontsize=14, fontweight='bold', pad=20)\n    _save(fig, output_dir / 'weekly_rank_heatmap.png', 'Weekly rank heatmap')\n\n    # Figure 7: Consistency Analysis\n    fig, ax = plt.subplots(figsize=(12, 8))\n    consistency = current_df.groupby('team_name').agg({\n        'weekly_rank': 'std',\n        'points_for': 'std'\n    }).reset_index()\n    consistency.columns = ['team_name', 'rank_std', 'points_std']\n    consistency = consistency.sort_values('rank_std', ascending=True)\n    colors_cons = ['#3498db' if x < consistency['rank_std'].median() else '#e67e22'\n                   for x in consistency['rank_std']]\n    bars = ax.barh(consistency['team_name'], consistency['rank_std'], color=colors_cons, alpha=0.8)\n    ax.set_xlabel('Standard Deviation of Weekly Rank', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Team Consistency - {latest_season} Season\\n(Lower = More Consistent)',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar in bars:\n        width = bar.get_width()\n        ax.text(width + 0.1, bar.get_y() + bar.get_height() / 2,\n                f'{width:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'consistency.png', 'Consistency leaderboard')\n\n    # Figure 8: Power Rankings Evolution by Week\n    fig, ax = plt.subplots(figsize=(14, 9))\n    season_df = df[df['season'] == latest_season].copy()\n    weekly_data = []\n    for week in sorted(season_df['week'].unique()):\n        week_df = season_df[season_df['week'] <= week].copy()\n        week_summary = week_df.groupby('team_name').agg({\n            'wins': 'sum',\n            'mvp_w': 'sum',\n            'top6_wins': 'sum'\n        }).reset_index()\n        week_summary['power_score'] = (week_summary['wins'] * 2) + week_summary['top6_wins'] + week_summary['mvp_w']\n        week_summary['power_rank'] = week_summary['power_score'].rank(ascending=False, method='min').astype(int)\n        week_summary['week'] = week\n        weekly_data.append(week_summary)\n    weekly_rankings = pd.concat(weekly_data, ignore_index=True)\n    teams = sorted(current_summary['team_name'].unique())\n    cmap = plt.get_cmap('tab20')\n    colors = cmap(np.linspace(0, 1, len(teams)))\n    for team, color in zip(teams, colors):\n        team_data = weekly_rankings[weekly_rankings['team_name'] == team].sort_values('week')\n        ax.plot(team_data['week'], team_data['power_score'], linewidth=2.5, label=team, color=color, alpha=0.8)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Cumulative Power Score', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Score Evolution - {latest_season} Season\\nHigher is Better', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3, linestyle='--')\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, framealpha=0.9)\n    _save(fig, output_dir / 'power_rankings_evolution.png', 'Power score evolution')\n\n\ndef save_summary_csv(summary: pd.DataFrame, filename: str | Path = 'team_summary.csv') -> Path:\n    \"\"\"Save summary table to CSV.\"\"\"\n    filepath = Path(filename)\n    _ensure_dir(filepath.parent or Path('.'))\n    summary.to_csv(filepath, index=False)\n    print(f\"✓ Saved summary table to: {filepath.as_posix()}\")\n    return filepath\n\n\ndef generate_markdown_analysis(summary: pd.DataFrame,\n                               filename: str | Path = 'power_rankings_analysis.md',\n                               visualization_dir: str | Path = VISUALIZATIONS_SUBDIR,\n                               matchup_data: Optional[pd.DataFrame] = None,\n                               player_data: Optional[pd.DataFrame] = None) -> Path:\n    \"\"\"Generate a snarky markdown analysis of the power rankings with optional AI commentary.\"\"\"\n    output_path = Path(filename)\n    _ensure_dir(output_path.parent or Path('.'))\n    visualization_dir = _ensure_dir(Path(visualization_dir))\n    visual_prefix = Path(os.path.relpath(visualization_dir, output_path.parent or Path('.'))).as_posix()\n    \n    use_ai_commentary = matchup_data is not None and player_data is not None\n\n    latest_season = summary['season'].max()\n    current_summary = summary[summary['season'] == latest_season].sort_values('power_rank')\n\n    def _viz(name: str) -> str:\n        return f\"{visual_prefix}/{name}\"\n\n    md = f\"\"\"# {latest_season} Fantasy Football Power Rankings Analysis\n## A Brutally Honest Assessment of Your League's Mediocrity\n\n---\n\n## Understanding the Metrics\n\nBefore we roast your teams, let's explain how we're measuring your mediocrity:\n\n### **Power Score** (The Overall Ranking)\n```\nPower Score = (Real Wins × 2) + (Top6 Wins) + (MVP-W)\n```\nThis weights actual matchup wins heavily while rewarding consistent high scoring.\n\n### **Real Wins**\nYour head-to-head record. Weighted 2× because wins matter.\n\n### **MVP-W** (Minimized Variance Potential Wins)\nYour theoretical win rate if you played every team each week.\n\n### **Top6 Wins**\nBinary metric for finishing in the top half of scorers.\n\n### **WAX** (Wins Above Expectation)\n```\nWAX = Real Wins - MVP-W\n```\nPositive = lucky. Negative = unlucky.\n\n---\n\n## Overall Power Rankings\n\n![Power Rankings]({_viz('power_rankings.png')})\n\n## Power Score Breakdown\n\n![Power Score Breakdown]({_viz('power_breakdown.png')})\n\n## Power Score Evolution Over Time\n\n![Power Score Evolution]({_viz('power_rankings_evolution.png')})\n\n*Cumulative power score by week - higher is better.*\n\n---\n\n## Team-by-Team Analysis (With the Snark You Deserve)\n\n\"\"\"\n\n    snark_templates = {\n        1: \"Congratulations, you're actually good. With {wins} wins and the highest scoring average in the league, you're not just getting lucky—you're genuinely dominating. That {wax:+.2f} WAX means you've earned almost every win.\",\n        2: \"Solidly in second place, you're doing everything right: consistent top-6 finishes, decent wins, and you're actually *slightly* unlucky ({wax:+.2f} WAX).\",\n    }\n\n    for _, row in current_summary.iterrows():\n        rank = int(row['power_rank'])\n        team = row['team_name']\n        wins = int(row['real_wins'])\n        losses = int(row['games_played'] - row['real_wins'])\n        ppg = row['ppg']\n        wax = row['wax']\n        power = row['power_score']\n        top6 = int(row['top6_wins'])\n        mvp_w = row['mvp_w']\n\n        if rank == 1:\n            analysis = snark_templates[1].format(wins=wins, wax=wax)\n        elif rank == 2:\n            analysis = snark_templates[2].format(wax=wax)\n        elif rank == 3:\n            if wax < -1.0:\n                analysis = (f\"Oh, {team}. You're scoring {ppg:.2f} PPG with {top6} top-6 finishes,\"\n                            f\" yet you're {wins}-{losses}. That {wax:+.2f} WAX is brutal.\")\n            else:\n                analysis = (f\"Legitimately good, but luck is on your side. {wax:+.2f} WAX means you've won\"\n                            f\" {abs(wax):.1f} more games than your scoring suggests.\")\n        elif rank <= 6:\n            if wax < -0.5:\n                analysis = (f\"Victim of bad luck with {wax:+.2f} WAX. {ppg:.2f} PPG and {top6} top-6 finishes\"\n                            \" should translate to more wins.\")\n            elif wax > 0.5:\n                analysis = (f\"You're getting some help from fate. {wax:+.2f} WAX means {abs(wax):.0f} gift wins.\")\n            else:\n                analysis = (f\"Solidly average. {wins}-{losses} with {ppg:.2f} PPG is exactly what you deserve.\")\n        elif rank == 7:\n            if wax > 1.5:\n                analysis = (f\"You beautiful fraud. #{rank} in power but {wins}-{losses} because of\"\n                            f\" {wax:+.2f} WAX. Schedule luck for days.\")\n            else:\n                analysis = (f\"Lower middle tier. {ppg:.2f} PPG and {wax:+.2f} WAX scream mediocrity.\")\n        elif rank <= 9:\n            if wax > 0.3:\n                analysis = (f\"Even with {wax:+.2f} WAX helping out, you're {wins}-{losses}.\"\n                            \" Imagine if you were unlucky?\")\n            else:\n                analysis = (f\"Fighting for scraps. {ppg:.2f} PPG and {wax:+.2f} WAX won't cut it.\")\n        elif rank == 10:\n            if wax > 0.5:\n                analysis = (f\"{wins} wins despite {ppg:.2f} PPG? {wax:+.2f} WAX says you're stealing victories.\")\n            else:\n                analysis = (f\"10th place with {ppg:.2f} PPG. Not unlucky—just not good enough.\")\n        elif rank == 11:\n            analysis = (f\"Second-to-last with {wins}-{losses}. {ppg:.2f} PPG and {wax:+.2f} WAX\"\n                        \" show you're getting exactly what you deserve.\")\n        else:\n            if wax < -0.5:\n                analysis = (f\"Dead last *and* unlucky ({wax:+.2f} WAX). The universe has jokes.\")\n            else:\n                analysis = (f\"Last place with {ppg:.2f} PPG. You're earning every painful loss.\")\n\n        ai_section = \"\"\n        if use_ai_commentary:\n            ai_text = generate_ai_commentary(team, matchup_data, player_data, row)\n            if ai_text:\n                ai_section = f\"\\n\\n**AI Weekly Recap:** {ai_text}\"\n\n        md += f\"\"\"### #{rank} {team} - Power Score: {power:.2f}\n**Record: {wins}-{losses} | PPG: {ppg:.2f} | WAX: {wax:+.2f}**  \n**Components: Real Wins: {wins} | Top6 Wins: {top6} | MVP-W: {mvp_w:.2f}**\n\n{analysis}{ai_section}\n\n---\n\n\"\"\"\n\n    md += \"\"\"\n## Final Thoughts\n\nThis league has one elite team, a cluster of contenders, a few lucky frauds, and some dumpster fires bringing up the rear. May the odds be ever in your favor.\n\n---\n\n*Power Rankings Formula: (Real Wins × 2) + (Top6 Wins) + (MVP-W)*  \n*WAX (Wins Above Expectation) = Real Wins - MVP-W*\n\"\"\"\n\n    output_path.write_text(md, encoding='utf-8')\n    print(f\"✓ Generated snarky analysis: {output_path.as_posix()}\")\n    return output_path\n\n\ndef run_analysis(team_stats_path: Path, report_dir: Path,\n                 matchups_path: Optional[Path] = None,\n                 player_stats_path: Optional[Path] = None) -> dict:\n    \"\"\"Execute the full analysis pipeline and return artifact paths.\"\"\"\n    report_dir = _ensure_dir(report_dir)\n    visualizations_dir = report_dir / VISUALIZATIONS_SUBDIR\n\n    df = load_data(team_stats_path)\n    summary = calculate_summary_stats(df)\n    print_summary_table(summary)\n\n    matchup_data = None\n    player_data = None\n    if matchups_path and matchups_path.exists():\n        matchup_data = pd.read_csv(matchups_path)\n        logging.info(\"Loaded matchup data for AI commentary: %d rows\", len(matchup_data))\n    if player_stats_path and player_stats_path.exists():\n        player_data = pd.read_csv(player_stats_path)\n        logging.info(\"Loaded player stats for AI commentary: %d rows\", len(player_data))\n\n    summary_csv = save_summary_csv(summary, report_dir / 'team_summary.csv')\n    markdown_path = generate_markdown_analysis(\n        summary,\n        report_dir / 'power_rankings_analysis.md',\n        visualizations_dir,\n        matchup_data=matchup_data,\n        player_data=player_data\n    )\n    create_visualizations(df, summary, visualizations_dir)\n\n    return {\n        'rows': len(df),\n        'seasons': df['season'].nunique(),\n        'teams': len(summary),\n        'summary_csv': summary_csv,\n        'markdown': markdown_path,\n        'visualizations_dir': visualizations_dir,\n    }\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description='Run the ESPN Fantasy Football analysis pipeline.')\n    parser.add_argument('--team-stats', default=DEFAULT_TEAM_STATS,\n                        help='Path to team_stats.csv (default: team_stats.csv)')\n    parser.add_argument('--report-dir', default=DEFAULT_REPORT_DIR,\n                        help='Directory to write summary, markdown, and visualizations (default: current directory)')\n    return parser.parse_args()\n\n\ndef main() -> None:\n    args = parse_args()\n    stats_path = Path(args.team_stats)\n    report_dir = Path(args.report_dir)\n\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ESPN FANTASY FOOTBALL ANALYSIS\")\n    print(\"=\" * 100)\n\n    artifacts = run_analysis(stats_path, report_dir)\n\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ANALYSIS COMPLETE!\")\n    print(\"=\" * 100)\n    print(\"\\nGenerated Files:\")\n    print(f\"  • {artifacts['summary_csv'].as_posix()} - Summary statistics table with Power Rankings\")\n    print(f\"  • {artifacts['markdown'].as_posix()} - Snarky written analysis with embedded images\")\n    viz_dir = artifacts['visualizations_dir'].as_posix()\n    print(f\"  • {viz_dir}/power_rankings.png - Overall power rankings\")\n    print(f\"  • {viz_dir}/power_breakdown.png - Power score component breakdown\")\n    print(f\"  • {viz_dir}/power_rankings_evolution.png - Weekly power rankings trends\")\n    print(f\"  • {viz_dir}/wax_leaderboard.png - Luck index ranking\")\n    print(f\"  • {viz_dir}/wins_vs_expected.png - Real wins vs expected wins\")\n    print(f\"  • {viz_dir}/total_points.png - Total points scored by team\")\n    print(f\"  • {viz_dir}/weekly_performance.png - Weekly scoring trends\")\n    print(f\"  • {viz_dir}/weekly_rank_heatmap.png - Weekly rankings grid\")\n    print(f\"  • {viz_dir}/consistency.png - Team consistency analysis\")\n    print(\"=\" * 100 + \"\\n\")\n\n\nif __name__ == '__main__':\n    main()\n","path":null,"size_bytes":27596,"size_tokens":null},"src/common/position_mapping.py":{"content":"\"\"\"ESPN Fantasy Football position mappings.\"\"\"\n\n# Position ID to position name mapping\nPOSITION_MAP = {\n    0: 'QB',\n    1: 'TQB',\n    2: 'RB',\n    3: 'RB/WR',\n    4: 'WR',\n    5: 'WR/TE',\n    6: 'TE',\n    7: 'OP',\n    8: 'DT',\n    9: 'DE',\n    10: 'LB',\n    11: 'DL',\n    12: 'CB',\n    13: 'S',\n    14: 'DB',\n    15: 'DP',\n    16: 'D/ST',\n    17: 'K',\n    18: 'P',\n    19: 'HC',\n    20: 'BE',\n    21: 'IR',\n    22: '',\n    23: 'RB/WR/TE',\n    24: 'ER',\n    25: 'Rookie'\n}\n\n# Lineup slot ID to slot name mapping\nLINEUP_SLOT_MAP = {\n    0: 'QB',\n    1: 'TQB',\n    2: 'RB',\n    3: 'RB/WR',\n    4: 'WR',\n    5: 'WR/TE',\n    6: 'TE',\n    7: 'OP',\n    8: 'DT',\n    9: 'DE',\n    10: 'LB',\n    11: 'DL',\n    12: 'CB',\n    13: 'S',\n    14: 'DB',\n    15: 'DP',\n    16: 'D/ST',\n    17: 'K',\n    18: 'P',\n    19: 'HC',\n    20: 'BENCH',\n    21: 'IR',\n    22: '',\n    23: 'FLEX',\n    24: 'ER',\n    25: 'Rookie'\n}\n","path":null,"size_bytes":900,"size_tokens":null},"src/scraper/espn_api.py":{"content":"\"\"\"ESPN Fantasy Football API interaction module.\"\"\"\nimport logging\nfrom typing import Any, Dict, Optional\n\nimport requests\n\nfrom src.common.config import ESPN_FF_BASE_URL\n\n\nclass ESPNFantasyAPI:\n    def __init__(self, league_id: int, season: int, espn_s2: Optional[str] = None, swid: Optional[str] = None):\n        self.league_id = league_id\n        self.season = season\n        self.base_url = ESPN_FF_BASE_URL\n        self.espn_s2 = espn_s2\n        self.swid = swid\n\n    def _get_cookies(self) -> Optional[Dict[str, str]]:\n        \"\"\"Build cookies dict for private league authentication.\"\"\"\n        if self.espn_s2 and self.swid:\n            return {\n                'espn_s2': self.espn_s2,\n                'SWID': self.swid\n            }\n        return None\n\n    def get_league_data(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch league data from ESPN API.\"\"\"\n        response = None\n        try:\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            cookies = self._get_cookies()\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                'Accept': 'application/json'\n            }\n            response = requests.get(url, cookies=cookies, headers=headers, timeout=30)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch league data: {e}\")\n            if response:\n                logging.error(f\"Response status: {response.status_code}\")\n            return None\n\n    def get_boxscore(self, week: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch boxscore data for a specific week.\"\"\"\n        try:\n            params = {\n                'scoringPeriodId': week,\n                'view': 'mMatchup'\n            }\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            cookies = self._get_cookies()\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                'Accept': 'application/json'\n            }\n            response = requests.get(url, params=params, cookies=cookies, headers=headers, timeout=30)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch boxscore for week {week}: {e}\")\n            return None\n\n    def validate_league(self) -> bool:\n        \"\"\"Validate if the league ID exists and is accessible.\"\"\"\n        try:\n            league_data = self.get_league_data()\n            return league_data is not None and 'id' in league_data\n        except Exception:\n            return False\n","path":null,"size_bytes":2810,"size_tokens":null},"src/scraper/data_processor.py":{"content":"\"\"\"Process and transform ESPN Fantasy Football data.\"\"\"\nimport logging\nfrom typing import Any, Dict\n\nimport pandas as pd\n\nfrom src.common.position_mapping import LINEUP_SLOT_MAP, POSITION_MAP\n\n\nclass DataProcessor:\n    def __init__(self, league_data: Dict[str, Any]):\n        self.league_data = league_data\n        self.teams_map = self._create_teams_map()\n\n    def _create_teams_map(self) -> Dict[int, str]:\n        \"\"\"Create a mapping of team IDs to team names.\"\"\"\n        teams_map = {}\n        try:\n            for team in self.league_data.get('teams', []):\n                # ESPN may have different name fields - try multiple options\n                team_id = team['id']\n                team_name = (\n                    team.get('name') or\n                    f\"{team.get('location', '')} {team.get('nickname', '')}\".strip() or\n                    team.get('abbrev', f'Team {team_id}')\n                )\n                teams_map[team_id] = team_name\n        except KeyError as e:\n            logging.error(f\"Error creating teams map: {e}\")\n        return teams_map\n\n    def process_matchups(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process matchup data into a DataFrame.\"\"\"\n        matchups = []\n\n        try:\n            for matchup in boxscore_data.get('schedule', []):\n                home_team_id = matchup['home']['teamId']\n                away_team_id = matchup['away']['teamId']\n                home_score = matchup['home']['totalPoints']\n                away_score = matchup['away']['totalPoints']\n\n                matchups.extend([\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': home_team_id,\n                        'team_name': self.teams_map.get(home_team_id, f'Team {home_team_id}'),\n                        'opponent_id': away_team_id,\n                        'opponent_name': self.teams_map.get(away_team_id, f'Team {away_team_id}'),\n                        'team_score': home_score,\n                        'opponent_score': away_score,\n                        'winner': home_score > away_score\n                    },\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': away_team_id,\n                        'team_name': self.teams_map.get(away_team_id, f'Team {away_team_id}'),\n                        'opponent_id': home_team_id,\n                        'opponent_name': self.teams_map.get(home_team_id, f'Team {home_team_id}'),\n                        'team_score': away_score,\n                        'opponent_score': home_score,\n                        'winner': away_score > home_score\n                    }\n                ])\n        except KeyError as e:\n            logging.error(f\"Error processing matchups: {e}\")\n\n        return pd.DataFrame(matchups)\n\n    def process_player_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process player statistics into a DataFrame.\"\"\"\n        player_stats = []\n\n        try:\n            for team in boxscore_data.get('teams', []):\n                team_id = team['id']\n                team_name = self.teams_map.get(team_id, f'Team {team_id}')\n\n                for player in team.get('roster', {}).get('entries', []):\n                    position_id = player['playerPoolEntry']['player']['defaultPositionId']\n                    slot_id = player['lineupSlotId']\n\n                    player_stats.append({\n                        'week': week,\n                        'team_id': team_id,\n                        'team_name': team_name,\n                        'player_id': player['playerId'],\n                        'player_name': player['playerPoolEntry']['player']['fullName'],\n                        'position': POSITION_MAP.get(position_id, f'POS_{position_id}'),\n                        'slot_position': LINEUP_SLOT_MAP.get(slot_id, f'SLOT_{slot_id}'),\n                        'points': player['playerPoolEntry']['appliedStatTotal'],\n                        'projected_points': player['playerPoolEntry'].get('projectedPointTotal', 0)\n                    })\n        except KeyError as e:\n            logging.error(f\"Error processing player stats: {e}\")\n\n        return pd.DataFrame(player_stats)\n\n    def process_team_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process team statistics into a DataFrame.\"\"\"\n        team_stats = []\n\n        try:\n            # Build team stats from matchup schedule data\n            team_points = {}\n            team_points_against = {}\n\n            for matchup in boxscore_data.get('schedule', []):\n                if matchup.get('matchupPeriodId') == week:\n                    home_id = matchup.get('home', {}).get('teamId')\n                    away_id = matchup.get('away', {}).get('teamId')\n                    home_points = matchup.get('home', {}).get('totalPoints', 0)\n                    away_points = matchup.get('away', {}).get('totalPoints', 0)\n\n                    if home_id and away_id:\n                        team_points[home_id] = home_points\n                        team_points[away_id] = away_points\n                        team_points_against[home_id] = away_points\n                        team_points_against[away_id] = home_points\n\n            # Sort teams by points\n            sorted_teams = sorted(team_points.items(), key=lambda x: x[1], reverse=True)\n\n            # Calculate stats for each team\n            total_teams = len(team_points)\n\n            for rank, (team_id, points) in enumerate(sorted_teams, 1):\n                points_against = team_points_against.get(team_id, 0)\n\n                # Wins: 1 if won matchup, 0 if lost\n                wins = 1 if points > points_against else 0\n\n                # Top6Wins: 1 if in top 6 scorers, 0 otherwise\n                top6_wins = 1 if rank <= 6 else 0\n\n                # mvp_w: all-play winning percentage\n                # Count how many teams this team would have beaten\n                teams_beaten = sum(1 for other_points in team_points.values() if points > other_points)\n                # Divide by number of other teams (total - 1)\n                mvp_w = teams_beaten / (total_teams - 1) if total_teams > 1 else 0\n\n                team_stats.append({\n                    'week': week,\n                    'team_id': team_id,\n                    'team_name': self.teams_map.get(team_id, f\"Team {team_id}\"),\n                    'points_for': points,\n                    'points_against': points_against,\n                    'weekly_rank': rank,\n                    'wins': wins,\n                    'top6_wins': top6_wins,\n                    'mvp_w': round(mvp_w, 4)\n                })\n        except (KeyError, TypeError) as e:\n            logging.error(f\"Error processing team stats: {e}\")\n\n        return pd.DataFrame(team_stats)\n","path":null,"size_bytes":6931,"size_tokens":null},"replit.md":{"content":"# SkatteBot - ESPN Fantasy Football Analyzer\n\n## Overview\n\nSkatteBot is a Python-based ESPN Fantasy Football data scraper and analysis tool. It pulls historical league data from ESPN's API, generates advanced statistical visualizations and power rankings, creates AI-powered snarky commentary, and delivers weekly email recaps with PDF reports.\n\nThe system processes matchup data, calculates custom metrics (Power Score, WAX/Wins Above Expectation, MVP-W), generates 9+ visualization charts, and emails results to league members.\n\n## User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n## System Architecture\n\n### Project Structure\nThe codebase follows a modular Python package structure under `src/`:\n- `src/scraper/` - ESPN API interaction and data collection\n- `src/analysis/` - Statistical analysis and visualization generation\n- `src/automation/` - Pipeline orchestration and email delivery\n- `src/common/` - Shared configuration and utilities\n\n### Data Flow Pipeline\n1. **Scraping**: ESPN API → Raw JSON → Processed DataFrames → CSV files in `data/latest/`\n2. **Analysis**: CSV files → Statistical calculations → Markdown reports + PNG charts in `reports/latest/`\n3. **Delivery**: Reports → PDF generation (WeasyPrint) → Email with attachments\n4. **Archiving**: Timestamped copies stored in `archive/<timestamp>/`\n\n### Key Design Decisions\n\n**ESPN API Integration**: Direct HTTP requests to ESPN's fantasy API endpoints with cookie-based authentication for private leagues. No official SDK used - custom implementation in `espn_api.py`.\n\n**Data Storage**: CSV files for persistence rather than a database. Simple, portable, and human-readable. Files organized into `data/` and `reports/` directories with `latest/` symlinks and timestamped archives.\n\n**Visualization**: Matplotlib + Seaborn for chart generation. Charts saved as PNG files and embedded in Markdown reports.\n\n**PDF Generation**: WeasyPrint converts Markdown → HTML → PDF for email attachments.\n\n**AI Commentary**: Uses Replit's built-in OpenAI integration (environment variables `AI_INTEGRATIONS_OPENAI_API_KEY` and `AI_INTEGRATIONS_OPENAI_BASE_URL`) for generating personalized team commentary.\n\n### Custom Metrics System\n- **Power Score**: Weighted composite of Real Wins (2×), Top6 Wins, and MVP-W\n- **MVP-W**: Theoretical win rate against all teams each week\n- **WAX**: Luck index (Real Wins - MVP-W)\n\n## External Dependencies\n\n### ESPN Fantasy API\n- Base URL: `https://lm-api-reads.fantasy.espn.com/apis/v3/games/ffl`\n- Authentication: `espn_s2` and `SWID` cookies for private leagues\n- Endpoints: League data, boxscores by week\n\n### OpenAI (via Replit Integration)\n- Used for AI-generated team commentary\n- Configured through Replit's built-in AI integration environment variables\n\n### Email (SMTP)\n- Configurable SMTP server for sending weekly reports\n- Supports Gmail and other SMTP providers\n- Requires: `SMTP_HOST`, `SMTP_PORT`, `SMTP_USERNAME`, `SMTP_PASSWORD`\n\n### Python Libraries\n- `pandas` - Data manipulation\n- `matplotlib`/`seaborn` - Visualizations\n- `requests` - HTTP client for ESPN API\n- `weasyprint` - PDF generation\n- `markdown` - Markdown to HTML conversion\n- `openai` - AI commentary generation\n\n### Required Secrets\n- `ESPN_S2`, `SWID` - ESPN authentication (private leagues)\n- `LEAGUE_ID` - ESPN league identifier\n- `YEARS` - Season year(s) to process\n- Email configuration secrets for delivery","path":null,"size_bytes":3436,"size_tokens":null},"src/analysis/__init__.py":{"content":"\"\"\"Analytics and reporting modules for Skattebot.\"\"\"\n","path":null,"size_bytes":53,"size_tokens":null},"src/scraper/__init__.py":{"content":"\"\"\"Scraper modules for ESPN data collection.\"\"\"\n","path":null,"size_bytes":48,"size_tokens":null},"power_rankings_analysis.md":{"content":"# 2025 Fantasy Football Power Rankings Analysis\n## A Brutally Honest Assessment of Your League's Mediocrity\n\n---\n\n## Understanding the Metrics\n\nBefore we roast your teams, let's explain how we're measuring your mediocrity:\n\n### **Power Score** (The Overall Ranking)\n```\nPower Score = (Real Wins × 2) + (Top6 Wins) + (MVP-W)\n```\nThis is our ultimate measure of team quality. It heavily weights **actual matchup wins** (multiplied by 2) because winning is what matters most. But it also rewards teams that consistently score in the top half (**Top6 Wins**) and would beat multiple opponents each week (**MVP-W**). A high power score means you're legitimately good, not just lucky.\n\n### **Real Wins**\nYour actual head-to-head record. Pretty simple: did you score more than your opponent? These are the only wins that show up in the standings, which is why they're weighted 2x in the Power Score.\n\n### **MVP-W** (Minimized Variance Potential Wins)\nThis is your theoretical win rate if you played **all teams in the league every single week**. \n\n**How it's calculated:**\n- Each week, we rank all 12 teams by their scores\n- Your MVP-W for that week = (number of teams you beat) ÷ (total teams - 1)\n- Example: If you scored 4th-highest in week 1, you beat 8 teams → MVP-W = 8/11 = 0.727\n\nSum this across all weeks, and you get your season MVP-W. It measures how dominant your scoring is regardless of who you actually played. High scorers have high MVP-W; low scorers don't.\n\n### **Top6 Wins**\nBinary metric: did you finish in the **top half** of scorers that week? \n- 1 point if you ranked #1-6 \n- 0 points if you ranked #7-12\n\nSum across all weeks. This rewards consistency—teams that regularly score well get more Top6 Wins. It's harder to fluke your way into consistent top-6 finishes than it is to steal a lucky head-to-head win.\n\n### **WAX** (Wins Above Expectation) - The Luck Index\n```\nWAX = Real Wins - MVP-W\n```\nThis tells you if you're **lucky or unlucky**:\n- **Positive WAX** = You're lucky (winning more games than your scoring deserves)\n- **Negative WAX** = You're unlucky (losing games despite good scoring)\n- **WAX near 0** = You're getting exactly what you deserve\n\nExample: If you have 6 real wins but only 4.0 MVP-W, your WAX is +2.0. That means you've won 2 more games than expected based on your scoring. You're benefiting from a favorable schedule or weak opponents having bad weeks against you.\n\n---\n\n## Overall Power Rankings\n\n![Power Rankings](visualizations/power_rankings.png)\n\n## Power Score Breakdown\n\n![Power Score Breakdown](visualizations/power_breakdown.png)\n\n## Power Score Evolution Over Time\n\n![Power Score Evolution](visualizations/power_rankings_evolution.png)\n\n*Cumulative power score by week - higher is better. Watch how teams' performances build throughout the season.*\n\n---\n\n## Team-by-Team Analysis (With the Snark You Deserve)\n\n### #1 MP - Power Score: 31.73\n**Record: 8-2 | PPG: 121.44 | WAX: +0.27**  \n**Components: Real Wins: 8 | Top6 Wins: 8 | MVP-W: 7.73**\n\nCongratulations, you're actually good. With 8 wins and the highest scoring average in the league, you're not just getting lucky—you're genuinely dominating. That +0.27 WAX means you've earned almost every win. The rest of the league is basically playing for second place at this point. Enjoy your inevitable championship and the awkward silence when you try to talk about your fantasy team at parties.\n\n---\n\n### #2 sgf - Power Score: 24.18\n**Record: 6-4 | PPG: 112.89 | WAX: -0.18**  \n**Components: Real Wins: 6 | Top6 Wins: 6 | MVP-W: 6.18**\n\nSolidly in second place, you're doing everything right: consistent top-6 finishes, decent wins, and you're actually *slightly* unlucky (-0.18 WAX). You're the tortoise to MP's hare, except the hare is already at the finish line and the tortoise is stuck in traffic. Still, you're legitimately good—just not good enough to catch the leader.\n\n---\n\n### #3 GV - Power Score: 23.36\n**Record: 6-4 | PPG: 103.66 | WAX: +0.64**  \n**Components: Real Wins: 6 | Top6 Wins: 6 | MVP-W: 5.36**\n\nLegitimately good, but let's be honest—you're getting a little help from the schedule gods. That +0.64 WAX means you've won 0.6 more games than your scoring suggests. Your 103.66 PPG is solid, but sitting at 6-4 is partly luck. Keep it up, but watch out for regression.\n\n---\n\n### #3 KIRK - Power Score: 23.36\n**Record: 5-5 | PPG: 111.27 | WAX: -1.36**  \n**Components: Real Wins: 5 | Top6 Wins: 7 | MVP-W: 6.36**\n\nOh, KIRK. You poor, unfortunate soul. You're scoring 111.27 PPG, finishing in the top 6 7 times, and somehow you're sitting at 5-5. That -1.36 WAX is brutal—you should have at least 6-4 by now. You're the fantasy football equivalent of a talented actor who never gets nominated for an Oscar. Maybe next week schedule some easier opponents? Oh wait, that's not how this works.\n\n---\n\n### #5 ZSF - Power Score: 22.64\n**Record: 5-5 | PPG: 111.25 | WAX: -0.64**  \n**Components: Real Wins: 5 | Top6 Wins: 7 | MVP-W: 5.64**\n\nAnother victim of bad luck with -0.64 WAX. You're scoring 111.25 PPG with 7 top-6 finishes, but sitting at 5-5 because apparently your opponents save their best weeks for you. The fantasy football scheduling algorithm clearly has it out for you. At least you can take solace in knowing you're better than your record suggests.\n\n---\n\n### #6 PATS - Power Score: 21.55\n**Record: 5-5 | PPG: 106.40 | WAX: -0.55**  \n**Components: Real Wins: 5 | Top6 Wins: 6 | MVP-W: 5.55**\n\nAnother victim of bad luck with -0.55 WAX. You're scoring 106.40 PPG with 6 top-6 finishes, but sitting at 5-5 because apparently your opponents save their best weeks for you. The fantasy football scheduling algorithm clearly has it out for you. At least you can take solace in knowing you're better than your record suggests.\n\n---\n\n### #7 GEMP - Power Score: 19.00\n**Record: 6-4 | PPG: 100.81 | WAX: +2.00**  \n**Components: Real Wins: 6 | Top6 Wins: 3 | MVP-W: 4.00**\n\nOh, GEMP. You beautiful, lucky bastard. You're ranked #7 in power but sitting at 6-4 because you have a league-leading +2.00 WAX. That means you've won TWO more games than your mediocre 100.81 PPG deserves. You're the kid who guesses on every test question and somehow passes. Enjoy your fraudulent record while it lasts—the fantasy gods giveth, and they definitely taketh away.\n\n---\n\n### #8 POO - Power Score: 18.45\n**Record: 5-5 | PPG: 102.37 | WAX: +0.55**  \n**Components: Real Wins: 5 | Top6 Wins: 4 | MVP-W: 4.45**\n\nEven with +0.55 WAX helping you out, you're still sitting at 5-5. That 102.37 PPG isn't doing you any favors. You're winning more than you should, and you're still struggling. Imagine if you were unlucky?\n\n---\n\n### #9 ROUX - Power Score: 17.09\n**Record: 4-6 | PPG: 96.72 | WAX: -0.09**  \n**Components: Real Wins: 4 | Top6 Wins: 5 | MVP-W: 4.09**\n\nFighting for scraps with a 4-6 record. That 96.72 PPG is bottom-tier, and your -0.09 WAX shows the fantasy gods aren't helping. Consistency isn't your strong suit. Neither is winning, apparently.\n\n---\n\n### #10 KESS - Power Score: 17.09\n**Record: 5-5 | PPG: 99.78 | WAX: +0.91**  \n**Components: Real Wins: 5 | Top6 Wins: 3 | MVP-W: 4.09**\n\nYou somehow have 5 wins despite a pathetic 99.78 PPG. That +0.91 WAX means you're winning games you have no business winning. You're like the relief pitcher who keeps giving up runs but somehow gets credited with wins. The most consistent thing about you is your ability to consistently underperform while still stumbling into victories.\n\n---\n\n### #11 WOOD - Power Score: 12.36\n**Record: 3-7 | PPG: 91.84 | WAX: -0.36**  \n**Components: Real Wins: 3 | Top6 Wins: 3 | MVP-W: 3.36**\n\nSecond-to-last with 3-7. Your 91.84 PPG is brutal, and even with -0.36 WAX, you can't escape the bottom. You're not just bad—you're bad AND getting exactly what you deserve. At least you're not in last place?\n\n---\n\n### #12 3000 - Power Score: 9.18\n**Record: 2-8 | PPG: 91.15 | WAX: -1.18**  \n**Components: Real Wins: 2 | Top6 Wins: 2 | MVP-W: 3.18**\n\nDead last. Basement dweller. The league's punching bag. You're scoring 91.15 PPG (worst in the league), you have 2 wins (also worst), and you're STILL unlucky (-1.18 WAX)! You should theoretically have 3 wins, but nope, even the universe has given up on you. The good news? You can only go up from here. The bad news? That's what you said last year.\n\n---\n\n\n## Final Thoughts\n\nThis league has: one elite team (MP), a cluster of above-average teams fighting for playoff spots, a bunch of lucky frauds (looking at you, GEMP), some genuinely unlucky squads (RIP KIRK), and absolute dumpster fires bringing up the rear (3000, we're still talking about you).\n\nMay the odds be ever in your favor. Or not. Based on these power rankings, most of you need more than luck—you need a miracle.\n\n---\n\n*Power Rankings Formula: (Real Wins × 2) + (Top6 Wins) + (MVP-W)*  \n*WAX (Wins Above Expectation) = Real Wins - MVP-W*  \n*Data through Week 10, 2025 Season*\n","path":null,"size_bytes":8901,"size_tokens":null}},"version":2}