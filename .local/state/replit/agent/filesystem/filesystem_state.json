{"file_contents":{"config.py":{"content":"\"\"\"Configuration settings for the ESPN Fantasy Football scraper.\"\"\"\n\n# ESPN API endpoints\nESPN_FF_BASE_URL = \"https://fantasy.espn.com/apis/v3/games/ffl\"\nLEAGUE_ENDPOINT = \"/seasons/{year}/segments/0/leagues/{league_id}\"\nBOXSCORE_ENDPOINT = \"/boxscore\"\n\n# API parameters\nDEFAULT_SEASON = 2023\nMAX_WEEK = 17\n\n# CSV output settings\nCSV_HEADERS = {\n    'matchups': [\n        'week', 'matchup_id', 'team_id', 'opponent_id',\n        'team_score', 'opponent_score', 'winner'\n    ],\n    'player_stats': [\n        'week', 'team_id', 'player_id', 'player_name',\n        'position', 'slot_position', 'points', 'projected_points'\n    ],\n    'team_stats': [\n        'week', 'team_id', 'team_name', 'points_for',\n        'points_against', 'weekly_rank'\n    ]\n}\n\n# Output file names\nOUTPUT_FILES = {\n    'matchups': 'matchups.csv',\n    'player_stats': 'player_stats.csv',\n    'team_stats': 'team_stats.csv'\n}\n","path":null,"size_bytes":895,"size_tokens":null},"csv_generator.py":{"content":"\"\"\"Generate CSV files from processed fantasy football data.\"\"\"\nimport pandas as pd\nfrom typing import Dict\nimport os\nimport logging\n\nclass CSVGenerator:\n    def __init__(self, output_dir: str = \".\"):\n        self.output_dir = output_dir\n        self._ensure_output_dir()\n\n    def _ensure_output_dir(self):\n        \"\"\"Ensure output directory exists.\"\"\"\n        try:\n            if not os.path.exists(self.output_dir):\n                os.makedirs(self.output_dir)\n        except OSError as e:\n            logging.error(f\"Failed to create output directory: {e}\")\n            raise\n\n    def save_dataframe(self, df: pd.DataFrame, filename: str):\n        \"\"\"Save DataFrame to CSV file.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            df.to_csv(output_path, index=False)\n            logging.info(f\"Successfully saved {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to save {filename}: {e}\")\n            raise\n\n    def append_to_csv(self, df: pd.DataFrame, filename: str):\n        \"\"\"Append DataFrame to existing CSV file or create new one.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            \n            if os.path.exists(output_path):\n                df.to_csv(output_path, mode='a', header=False, index=False)\n            else:\n                df.to_csv(output_path, index=False)\n                \n            logging.info(f\"Successfully appended to {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to append to {filename}: {e}\")\n            raise\n","path":null,"size_bytes":1593,"size_tokens":null},"espn_ff_scraper.py":{"content":"\"\"\"Main script for ESPN Fantasy Football data scraping.\"\"\"\nimport argparse\nimport logging\nfrom datetime import datetime\nimport sys\nfrom typing import Optional\n\nfrom espn_api import ESPNFantasyAPI\nfrom data_processor import DataProcessor\nfrom csv_generator import CSVGenerator\nfrom config import DEFAULT_SEASON, MAX_WEEK, OUTPUT_FILES\n\ndef setup_logging():\n    \"\"\"Configure logging settings.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n\ndef parse_arguments():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='ESPN Fantasy Football Data Scraper')\n    parser.add_argument('--league_id', type=int, required=True,\n                      help='ESPN Fantasy Football League ID')\n    parser.add_argument('--season', type=int, default=DEFAULT_SEASON,\n                      help=f'Season year (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int,\n                      help=f'Specific week to scrape (default: all weeks)')\n    parser.add_argument('--output', type=str, default='.',\n                      help='Output directory for CSV files')\n    return parser.parse_args()\n\ndef validate_arguments(args) -> bool:\n    \"\"\"Validate command line arguments.\"\"\"\n    if args.season < 2010 or args.season > datetime.now().year:\n        logging.error(f\"Invalid season year: {args.season}\")\n        return False\n    \n    if args.week and (args.week < 1 or args.week > MAX_WEEK):\n        logging.error(f\"Invalid week number: {args.week}\")\n        return False\n        \n    return True\n\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    setup_logging()\n    args = parse_arguments()\n    \n    if not validate_arguments(args):\n        sys.exit(1)\n\n    # Initialize components\n    api = ESPNFantasyAPI(args.league_id, args.season)\n    csv_generator = CSVGenerator(args.output)\n\n    # Validate league\n    if not api.validate_league():\n        logging.error(f\"Invalid or inaccessible league ID: {args.league_id}\")\n        sys.exit(1)\n\n    # Get league data\n    league_data = api.get_league_data()\n    if not league_data:\n        logging.error(\"Failed to fetch league data\")\n        sys.exit(1)\n\n    data_processor = DataProcessor(league_data)\n    \n    # Determine weeks to process\n    weeks = [args.week] if args.week else range(1, MAX_WEEK + 1)\n    \n    for week in weeks:\n        logging.info(f\"Processing week {week}...\")\n        \n        # Fetch boxscore data\n        boxscore_data = api.get_boxscore(week)\n        if not boxscore_data:\n            logging.warning(f\"Skipping week {week} - no data available\")\n            continue\n\n        try:\n            # Process data\n            matchups_df = data_processor.process_matchups(boxscore_data, week)\n            player_stats_df = data_processor.process_player_stats(boxscore_data, week)\n            team_stats_df = data_processor.process_team_stats(boxscore_data, week)\n\n            # Save to CSV\n            csv_generator.append_to_csv(matchups_df, OUTPUT_FILES['matchups'])\n            csv_generator.append_to_csv(player_stats_df, OUTPUT_FILES['player_stats'])\n            csv_generator.append_to_csv(team_stats_df, OUTPUT_FILES['team_stats'])\n            \n            logging.info(f\"Successfully processed week {week}\")\n            \n        except Exception as e:\n            logging.error(f\"Error processing week {week}: {e}\")\n            continue\n\n    logging.info(\"Data scraping completed successfully\")\n\nif __name__ == \"__main__\":\n    main()\n","path":null,"size_bytes":3590,"size_tokens":null},"espn_api.py":{"content":"\"\"\"ESPN Fantasy Football API interaction module.\"\"\"\nimport requests\nfrom typing import Dict, Any, Optional\nimport logging\n\nclass ESPNFantasyAPI:\n    def __init__(self, league_id: int, season: int):\n        self.league_id = league_id\n        self.season = season\n        self.base_url = \"https://fantasy.espn.com/apis/v3/games/ffl\"\n        \n    def get_league_data(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch league data from ESPN API.\"\"\"\n        try:\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            response = requests.get(url)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch league data: {e}\")\n            return None\n\n    def get_boxscore(self, week: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch boxscore data for a specific week.\"\"\"\n        try:\n            params = {\n                'scoringPeriodId': week,\n                'view': ['mBoxscore', 'mMatchupScore']\n            }\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}/matchups\"\n            response = requests.get(url, params=params)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch boxscore for week {week}: {e}\")\n            return None\n\n    def validate_league(self) -> bool:\n        \"\"\"Validate if the league ID exists and is accessible.\"\"\"\n        try:\n            league_data = self.get_league_data()\n            return league_data is not None and 'id' in league_data\n        except Exception:\n            return False\n","path":null,"size_bytes":1763,"size_tokens":null},"README.md":{"content":"# ESPN Fantasy Football Scraper & Newsletter\n\nAn end-to-end toolkit that scrapes ESPN Fantasy Football data, builds power-ranking visualizations, archives weekly artifacts, and emails a Tuesday-morning recap. The core logic now lives inside the `src/` package so it can be reused locally, on Replit, or in any scheduled worker.\n\n## Feature Highlights\n- Multi-season scraping with automatic filtering of unplayed weeks.\n- Analysis pipeline that creates `team_summary.csv`, a snarky markdown newsletter, and nine Matplotlib/Seaborn visuals.\n- Automation runner (`src/automation/runner.py`) that orchestrates scrape → analysis → archiving → email.\n- Directory hygiene: latest outputs live in `data/latest/` and `reports/latest/`; immutable snapshots are stored under `archive/<timestamp>/`.\n- SMTP notifications with attachments so the recap lands in your inbox without pulling files manually.\n\n## Quick Start\n\n### Manual scrape + analysis\n```bash\npython -m src.scraper.espn_ff_scraper --league_id YOUR_LEAGUE_ID --years 2024 2025 --output ./data/latest\npython -m src.analysis.team_analysis ./data/latest/team_stats.csv ./reports/latest\n```\n- CSVs land in `data/latest/`.\n- Markdown + PNGs land in `reports/latest/`.\n- Copy both folders somewhere safe if you want historical snapshots.\n\n### One-shot automation + email\n```bash\npython -m src.automation.runner --league-id YOUR_LEAGUE_ID --years 2024 2025 --verbose\n```\nThe runner wipes yesterday's artifacts, runs the scraper + analysis, archives the results, and emails the summary CSV + markdown newsletter whenever SMTP secrets are set.\n\n### Artifact directories\n- `data/latest/`: fresh CSV exports (`matchups.csv`, `player_stats.csv`, `team_stats.csv`).\n- `reports/latest/`: `team_summary.csv`, `power_rankings_analysis.md`, and charts.\n- `archive/<timestamp>/`: timestamped copy of both folders for future reference.\n\n## Secrets & Environment\n\n| Key | Required | Purpose |\n| --- | --- | --- |\n| `ESPN_S2` | Private leagues | ESPN auth cookie (long string) |\n| `SWID` | Private leagues | ESPN auth cookie with braces |\n| `EMAIL_FROM` | Optional | Sender address for recap email |\n| `EMAIL_TO` | Optional | Comma-separated recipients |\n| `SMTP_HOST` / `SMTP_PORT` | Optional | Mail server + port (default 587) |\n| `SMTP_USERNAME` / `SMTP_PASSWORD` | Optional | SMTP credentials |\n| `LEAGUE_ID`, `YEARS` | Optional | Helpful for scheduled deployments (see `.replit`) |\n\n**How to capture ESPN cookies**\n1. Log in to https://fantasy.espn.com and load your league page.\n2. Open browser dev tools (`F12`) → Application/Storage tab.\n3. Expand **Cookies → https://fantasy.espn.com**.\n4. Copy the values for `espn_s2` and `SWID` (keep the braces).\n5. Store them as `ESPN_S2` and `SWID` secrets (never commit these values).\n\n## Project Architecture\n```\nsrc/\n├─ common/\n│  ├─ config.py              # shared constants, defaults, CSV names\n│  └─ position_mapping.py    # slot/position maps for ESPN IDs\n├─ scraper/\n│  ├─ espn_ff_scraper.py     # CLI + scrape_league helper\n│  ├─ espn_api.py            # ESPN HTTP client\n│  ├─ data_processor.py      # dataframe builders\n│  └─ csv_generator.py       # type-safe CSV writer\n├─ analysis/\n│  └─ team_analysis.py       # power rankings, charts, markdown\n└─ automation/\n   └─ runner.py              # scrape → analyze → archive → email\n```\nSupporting folders:\n- `data/`, `reports/`, `archive/`: contain generated artifacts (git-ignored except for `.gitkeep`).\n- `visualizations/`: checked-in gallery for reference.\n\n## Workflow Details\n1. **Scrape data** (manual): `python -m src.scraper.espn_ff_scraper --league_id ... --years ...`.\n2. **Analyze data**: `python -m src.analysis.team_analysis ./data/latest/team_stats.csv ./reports/latest`.\n3. **Automate everything**: `python -m src.automation.runner --league-id ... --years ...`.\n4. **Email recap**: provide SMTP + email env vars so the runner can send attachments (`team_summary.csv` + `power_rankings_analysis.md`).\n5. **Archive**: every automation run copies `data/latest/` and `reports/latest/` into `archive/<UTC timestamp>/` for long-term storage.\n\n## Power Rankings & Visualizations\n`team_analysis.py` produces the following assets on each run:\n1. `power_rankings.png` — leaderboard sorted by power score.\n2. `power_breakdown.png` — stacked bars of Real Wins, Top6 Wins, MVP-W.\n3. `power_rankings_evolution.png` — line chart for weekly ranking shifts.\n4. `wax_leaderboard.png` — Wins Above Expectation comparison.\n5. `wins_vs_expected.png` — scatter of real vs expected wins.\n6. `total_points.png` — season-long points for each team.\n7. `weekly_performance.png` — trends of weekly scoring.\n8. `weekly_rank_heatmap.png` — heatmap of weekly ranks.\n9. `consistency.png` — variation in scoring week over week.\n10. `power_rankings_analysis.md` — narrative report with snark + embedded charts.\n\n## Command Reference\n\n### Scraper (`src.scraper.espn_ff_scraper`)\n| Option | Description | Required | Default |\n| --- | --- | --- | --- |\n| `--league_id` | ESPN Fantasy Football League ID | Yes | — |\n| `--years` | One or more seasons to fetch | No | current season |\n| `--week` | Specific week (otherwise all played weeks) | No | All |\n| `--output` | Output directory for CSVs | No | `.` |\n\n### Automation runner (`src.automation.runner`)\n| Option | Description | Required | Default |\n| --- | --- | --- | --- |\n| `--league-id` | ESPN league ID | Yes | — |\n| `--years` | Season list | No | current season |\n| `--week` | Limit to a single week | No | all played weeks |\n| `--email-to` / `--email-from` | Override email env vars | No | env |\n| `--smtp-host` / `--smtp-port` | Override SMTP env vars | No | env/587 |\n| `--smtp-username` / `--smtp-password` | SMTP credentials | No | env |\n| `--smtp-disable-tls` | Use SSL instead of STARTTLS | No | STARTTLS |\n| `--verbose` | Debug logging | No | info |\n\n## Output Files\nAll CSVs include a `season` column so you can combine multiple years safely.\n- `matchups.csv`: week-by-week matchups including opponent, score, and result.\n- `player_stats.csv`: per-player scoring with slot/position labels.\n- `team_stats.csv`: team totals plus advanced metrics (weekly rank, Top6 wins, MVP-W, WAX inputs).\n- `team_summary.csv`: rollup used for power rankings and newsletter narrative.\n\n## Automation & Hosting\n- `.replit` runs `python -m src.automation.runner` by default so the Run button performs the full pipeline.\n- `replit.md` details how to add secrets, override args, and schedule weekly runs with Replit Deployments.\n\n## Troubleshooting\n- **403 Forbidden**: ESPN cookies missing or expired. Refresh `ESPN_S2` and `SWID`.\n- **Invalid league ID**: double-check the numeric ID in the league URL and ensure you have access for each requested season.\n- **No email**: confirm SMTP host/credentials plus `EMAIL_FROM`/`EMAIL_TO`. Run with `--verbose` for SMTP logs.\n- **No charts**: verify `team_stats.csv` exists in `data/latest/` before running the analysis step.\n\n## Privacy & Security\n- Never commit secrets; store them in Replit/Vercel/your host's secret manager.\n- ESPN cookies expire periodically—treat them like passwords and rotate when scraping fails.\n- Archives may contain sensitive matchup data; share them carefully.\n\n## Git + GitHub Workflow\n1. `git init && git add . && git commit -m \"Initial import\"`.\n2. Create a GitHub repo, then:\n   ```bash\n   git branch -M main\n   git remote add origin https://github.com/<user>/<repo>.git\n   git push -u origin main\n   ```\n3. Use feature branches for enhancements and keep generated artifacts out of version control (already handled via `.gitignore`).\n## Replit Setup\n1. Import this repo into a Python Replit and open the Shell.\n2. Run `pip install -r requirements.txt` once (or let the `.replit` hook do it automatically on first run).\n3. Add the required secrets under **Tools → Secrets** (`ESPN_S2`, `SWID`, optional SMTP keys).\n4. Hit **Run**—Replit executes `python -m src.automation.runner` per `.replit`, generating fresh data, reports, and archive snapshots.\n5. For custom flags, stop the default run and execute the desired CLI command in the Shell.\n\n## src Modules at a Glance\n| Folder | Responsibility | Typical Consumers |\n| --- | --- | --- |\n| `common/` | Shared config values, ID/position maps | All downstream code |\n| `scraper/` | HTTP calls, parsing, CSV emission | Automation runner, manual scrape |\n| `analysis/` | Power-ranking math, charts, newsletter | Automation runner, manual analysis |\n| `automation/` | Orchestrates scrape → analyze → archive → email | Replit/cron jobs |\n\n```mermaid\nflowchart TD\n   subgraph Common\n      C1[common/config.py]\n      C2[common/position_mapping.py]\n   end\n   subgraph Scraper\n      S1[espn_ff_scraper.py\\nCLI + orchestration]\n      S2[espn_api.py\\nESPN HTTP client]\n      S3[data_processor.py\\nBuild DataFrames]\n      S4[csv_generator.py\\nPersist typed CSVs]\n   end\n   subgraph Analysis\n      A1[team_analysis.py\\nRankings + visuals + markdown]\n   end\n   subgraph Automation\n      R1[automation/runner.py\\nPipeline controller]\n   end\n   R1 --> S1\n   S1 --> S2\n   S1 --> S3\n   S3 --> S4\n   S4 -->|CSVs| A1\n   R1 --> A1\n   C1 --> S1\n   C1 --> S3\n   C1 --> A1\n   C2 --> S3\n   A1 -->|Reports & Charts| R1\n```\n","path":null,"size_bytes":9298,"size_tokens":null},"data_processor.py":{"content":"\"\"\"Process and transform ESPN Fantasy Football data.\"\"\"\nimport pandas as pd\nfrom typing import Dict, List, Any\nimport logging\n\nclass DataProcessor:\n    def __init__(self, league_data: Dict[str, Any]):\n        self.league_data = league_data\n        self.teams_map = self._create_teams_map()\n\n    def _create_teams_map(self) -> Dict[int, str]:\n        \"\"\"Create a mapping of team IDs to team names.\"\"\"\n        teams_map = {}\n        try:\n            for team in self.league_data.get('teams', []):\n                teams_map[team['id']] = team['name']\n        except KeyError as e:\n            logging.error(f\"Error creating teams map: {e}\")\n        return teams_map\n\n    def process_matchups(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process matchup data into a DataFrame.\"\"\"\n        matchups = []\n        \n        try:\n            for matchup in boxscore_data.get('schedule', []):\n                home_team_id = matchup['home']['teamId']\n                away_team_id = matchup['away']['teamId']\n                home_score = matchup['home']['totalPoints']\n                away_score = matchup['away']['totalPoints']\n                \n                matchups.extend([\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': home_team_id,\n                        'opponent_id': away_team_id,\n                        'team_score': home_score,\n                        'opponent_score': away_score,\n                        'winner': home_score > away_score\n                    },\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': away_team_id,\n                        'opponent_id': home_team_id,\n                        'team_score': away_score,\n                        'opponent_score': home_score,\n                        'winner': away_score > home_score\n                    }\n                ])\n        except KeyError as e:\n            logging.error(f\"Error processing matchups: {e}\")\n            \n        return pd.DataFrame(matchups)\n\n    def process_player_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process player statistics into a DataFrame.\"\"\"\n        player_stats = []\n        \n        try:\n            for team in boxscore_data.get('teams', []):\n                team_id = team['id']\n                \n                for player in team.get('roster', {}).get('entries', []):\n                    player_stats.append({\n                        'week': week,\n                        'team_id': team_id,\n                        'player_id': player['playerId'],\n                        'player_name': player['playerPoolEntry']['player']['fullName'],\n                        'position': player['playerPoolEntry']['player']['defaultPositionId'],\n                        'slot_position': player['lineupSlotId'],\n                        'points': player['playerPoolEntry']['appliedStatTotal'],\n                        'projected_points': player['playerPoolEntry'].get('projectedPointTotal', 0)\n                    })\n        except KeyError as e:\n            logging.error(f\"Error processing player stats: {e}\")\n            \n        return pd.DataFrame(player_stats)\n\n    def process_team_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process team statistics into a DataFrame.\"\"\"\n        team_stats = []\n        \n        try:\n            teams_data = boxscore_data.get('teams', [])\n            sorted_teams = sorted(teams_data, key=lambda x: x['points'], reverse=True)\n            \n            for rank, team in enumerate(sorted_teams, 1):\n                team_stats.append({\n                    'week': week,\n                    'team_id': team['id'],\n                    'team_name': self.teams_map.get(team['id'], f\"Team {team['id']}\"),\n                    'points_for': team['points'],\n                    'points_against': team['pointsAgainst'],\n                    'weekly_rank': rank\n                })\n        except KeyError as e:\n            logging.error(f\"Error processing team stats: {e}\")\n            \n        return pd.DataFrame(team_stats)\n","path":null,"size_bytes":4249,"size_tokens":null},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"matplotlib>=3.10.7\",\n    \"numpy>=2.2.2\",\n    \"pandas>=2.2.3\",\n    \"requests>=2.32.3\",\n    \"seaborn>=0.13.2\",\n]\n","path":null,"size_bytes":258,"size_tokens":null},"src/common/__init__.py":{"content":"\"\"\"Common utilities for Skattebot.\"\"\"\n","path":null,"size_bytes":38,"size_tokens":null},"src/automation/__init__.py":{"content":"\"\"\"Automation orchestration for Skattebot.\"\"\"\n","path":null,"size_bytes":46,"size_tokens":null},"src/automation/runner.py":{"content":"\"\"\"Automation runner for scheduled ESPN Fantasy Football reporting.\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport mimetypes\nimport os\nimport shutil\nimport smtplib\nfrom datetime import datetime\nfrom email.message import EmailMessage\nfrom pathlib import Path\nfrom typing import List, Sequence\n\nfrom src.analysis.team_analysis import run_analysis\nfrom src.common.config import DEFAULT_SEASON\nfrom src.scraper.espn_ff_scraper import scrape_league\n\nBASE_DIR = Path(__file__).resolve().parents[2]\nDATA_LATEST_DIR = BASE_DIR / 'data' / 'latest'\nREPORT_LATEST_DIR = BASE_DIR / 'reports' / 'latest'\nARCHIVE_ROOT = BASE_DIR / 'archive'\n\n\ndef configure_logging(verbose: bool = False) -> None:\n    level = logging.DEBUG if verbose else logging.INFO\n    logging.basicConfig(\n        level=level,\n        format='%(asctime)s - %(levelname)s - %(message)s'\n    )\n\n\ndef reset_directory(path: Path) -> Path:\n    if path.exists():\n        shutil.rmtree(path)\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n\n\ndef archive_run(data_dir: Path, report_dir: Path) -> Path:\n    ARCHIVE_ROOT.mkdir(parents=True, exist_ok=True)\n    timestamp = datetime.utcnow().strftime('%Y%m%dT%H%M%SZ')\n    run_dir = ARCHIVE_ROOT / timestamp\n    shutil.copytree(data_dir, run_dir / 'data')\n    shutil.copytree(report_dir, run_dir / 'reports')\n    logging.info(\"Archived artifacts to %s\", run_dir)\n    return run_dir\n\n\ndef parse_recipients(raw: str | None) -> List[str]:\n    if not raw:\n        return []\n    return [item.strip() for item in raw.split(',') if item.strip()]\n\n\ndef build_email(subject: str,\n                body: str,\n                sender: str,\n                recipients: Sequence[str],\n                attachments: Sequence[Path]) -> EmailMessage:\n    msg = EmailMessage()\n    msg['Subject'] = subject\n    msg['From'] = sender\n    msg['To'] = ', '.join(recipients)\n    msg.set_content(body)\n\n    for attachment in attachments:\n        if not attachment.exists():\n            logging.warning(\"Attachment %s not found; skipping\", attachment)\n            continue\n        mime_type, _ = mimetypes.guess_type(attachment.name)\n        maintype, subtype = (mime_type or 'application/octet-stream').split('/', 1)\n        msg.add_attachment(\n            attachment.read_bytes(),\n            maintype=maintype,\n            subtype=subtype,\n            filename=attachment.name\n        )\n    return msg\n\n\ndef send_email(message: EmailMessage,\n               host: str,\n               port: int,\n               username: str | None,\n               password: str | None,\n               use_tls: bool = True) -> None:\n    smtp = smtplib.SMTP(host, port) if use_tls else smtplib.SMTP_SSL(host, port)\n    with smtp:\n        if use_tls:\n            smtp.ehlo()\n            smtp.starttls()\n            smtp.ehlo()\n        if username and password:\n            smtp.login(username, password)\n        smtp.send_message(message)\n        logging.info(\"Sent notification email to %s\", message['To'])\n\n\ndef run(args: argparse.Namespace) -> None:\n    configure_logging(args.verbose)\n\n    logging.info(\"Preparing directories\")\n    reset_directory(DATA_LATEST_DIR)\n    reset_directory(REPORT_LATEST_DIR)\n\n    logging.info(\"Starting scraper for league %s\", args.league_id)\n    scrape_league(\n        league_id=args.league_id,\n        years=args.years,\n        week=args.week,\n        output_dir=str(DATA_LATEST_DIR)\n    )\n\n    team_stats_path = DATA_LATEST_DIR / 'team_stats.csv'\n    if not team_stats_path.exists():\n        raise FileNotFoundError(f\"Expected {team_stats_path} to exist after scraping\")\n\n    logging.info(\"Running analysis step\")\n    artifacts = run_analysis(team_stats_path, REPORT_LATEST_DIR)\n\n    archive_dir = archive_run(DATA_LATEST_DIR, REPORT_LATEST_DIR)\n\n    recipients = parse_recipients(args.email_to or os.getenv('EMAIL_TO'))\n    sender = args.email_from or os.getenv('EMAIL_FROM')\n\n    smtp_host = args.smtp_host or os.getenv('SMTP_HOST')\n    smtp_port = int(args.smtp_port or os.getenv('SMTP_PORT', '587'))\n    smtp_user = args.smtp_username or os.getenv('SMTP_USERNAME')\n    smtp_pass = args.smtp_password or os.getenv('SMTP_PASSWORD')\n    use_tls = not args.smtp_disable_tls\n\n    if recipients and sender and smtp_host:\n        subject = f\"ESPN Fantasy Recap - {datetime.utcnow():%Y-%m-%d}\"\n        body = (\n            f\"Weekly scrape completed for league {args.league_id}.\\n\"\n            f\"Seasons processed: {', '.join(map(str, args.years))}\\n\"\n            f\"Rows analyzed: {artifacts['rows']}\\n\"\n            f\"Teams summarized: {artifacts['teams']}\\n\"\n            f\"Archive: {archive_dir.relative_to(BASE_DIR)}\\n\\n\"\n            \"Attachments include the latest summary CSV and markdown newsletter.\"\n        )\n        attachments = [artifacts['summary_csv'], artifacts['markdown']]\n        message = build_email(subject, body, sender, recipients, attachments)\n        send_email(message, smtp_host, smtp_port, smtp_user, smtp_pass, use_tls=use_tls)\n    else:\n        logging.info(\"Email configuration incomplete; skipping notification\")\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description='Automate scraping, analysis, archiving, and notifications.')\n    parser.add_argument('--league-id', type=int, required=True, help='ESPN Fantasy Football League ID')\n    parser.add_argument('--years', type=int, nargs='+', default=[DEFAULT_SEASON],\n                        help=f'Season year(s) to scrape (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int, help='Specific week to scrape (default: all weeks)')\n    parser.add_argument('--email-to', help='Comma-separated recipient list (overrides EMAIL_TO env)')\n    parser.add_argument('--email-from', help='Sender email (overrides EMAIL_FROM env)')\n    parser.add_argument('--smtp-host', help='SMTP host (overrides SMTP_HOST env)')\n    parser.add_argument('--smtp-port', help='SMTP port (default/env: 587)')\n    parser.add_argument('--smtp-username', help='SMTP username (overrides SMTP_USERNAME env)')\n    parser.add_argument('--smtp-password', help='SMTP password (overrides SMTP_PASSWORD env)')\n    parser.add_argument('--smtp-disable-tls', action='store_true', help='Use SSL instead of STARTTLS')\n    parser.add_argument('--verbose', action='store_true', help='Enable debug logging')\n    return parser.parse_args()\n\n\nif __name__ == '__main__':\n    run(parse_args())\n","path":null,"size_bytes":6398,"size_tokens":null},"src/common/config.py":{"content":"\"\"\"Configuration settings for the ESPN Fantasy Football scraper.\"\"\"\n\n# ESPN API endpoints\nESPN_FF_BASE_URL = \"https://lm-api-reads.fantasy.espn.com/apis/v3/games/ffl\"\nLEAGUE_ENDPOINT = \"/seasons/{year}/segments/0/leagues/{league_id}\"\nBOXSCORE_ENDPOINT = \"/boxscore\"\n\n# API parameters\nDEFAULT_SEASON = 2023\nMAX_WEEK = 17\n\n# CSV output settings\nCSV_HEADERS = {\n    'matchups': [\n        'week', 'matchup_id', 'team_id', 'team_name', 'opponent_id', 'opponent_name',\n        'team_score', 'opponent_score', 'winner', 'season'\n    ],\n    'player_stats': [\n        'week', 'team_id', 'team_name', 'player_id', 'player_name',\n        'position', 'slot_position', 'points', 'projected_points', 'season'\n    ],\n    'team_stats': [\n        'week', 'team_id', 'team_name', 'points_for',\n        'points_against', 'weekly_rank', 'wins', 'top6_wins', 'mvp_w', 'season'\n    ]\n}\n\n# Output file names\nOUTPUT_FILES = {\n    'matchups': 'matchups.csv',\n    'player_stats': 'player_stats.csv',\n    'team_stats': 'team_stats.csv'\n}\n","path":null,"size_bytes":1011,"size_tokens":null},"src/scraper/espn_ff_scraper.py":{"content":"\"\"\"Main script for ESPN Fantasy Football data scraping.\"\"\"\nimport argparse\nimport logging\nimport os\nimport sys\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom src.common.config import DEFAULT_SEASON, MAX_WEEK, OUTPUT_FILES\nfrom src.scraper.csv_generator import CSVGenerator\nfrom src.scraper.data_processor import DataProcessor\nfrom src.scraper.espn_api import ESPNFantasyAPI\n\n\ndef setup_logging():\n    \"\"\"Configure logging settings.\"\"\"\n    logging.basicConfig(\n        level=logging.INFO,\n        format='%(asctime)s - %(levelname)s - %(message)s',\n        handlers=[\n            logging.StreamHandler(sys.stdout)\n        ]\n    )\n\n\ndef parse_arguments():\n    \"\"\"Parse command line arguments.\"\"\"\n    parser = argparse.ArgumentParser(description='ESPN Fantasy Football Data Scraper')\n    parser.add_argument('--league_id', type=int, required=True,\n                        help='ESPN Fantasy Football League ID')\n    parser.add_argument('--years', type=int, nargs='+', default=[DEFAULT_SEASON],\n                        help=f'Season year(s) to scrape - can specify multiple (default: {DEFAULT_SEASON})')\n    parser.add_argument('--week', type=int,\n                        help='Specific week to scrape (default: all weeks)')\n    parser.add_argument('--output', type=str, default='.',\n                        help='Output directory for CSV files')\n    return parser.parse_args()\n\n\ndef validate_arguments(args) -> bool:\n    \"\"\"Validate command line arguments.\"\"\"\n    current_year = datetime.now().year\n    for year in args.years:\n        if year < 2010 or year > current_year:\n            logging.error(f\"Invalid season year: {year}\")\n            return False\n\n    if args.week and (args.week < 1 or args.week > MAX_WEEK):\n        logging.error(f\"Invalid week number: {args.week}\")\n        return False\n\n    return True\n\n\ndef clear_existing_csv_files(output_dir: str):\n    \"\"\"Clear existing CSV files before starting a new scrape.\"\"\"\n    csv_files = [OUTPUT_FILES['matchups'], OUTPUT_FILES['player_stats'], OUTPUT_FILES['team_stats']]\n\n    for csv_file in csv_files:\n        file_path = os.path.join(output_dir, csv_file)\n        if os.path.exists(file_path):\n            os.remove(file_path)\n            logging.info(f\"Cleared existing file: {csv_file}\")\n\n\ndef has_week_been_played(boxscore_data: dict, requested_week: int) -> bool:\n    \"\"\"Check if a week has been played by finding matchups for that specific week.\n\n    ESPN returns all matchups for the season in the 'schedule' field.\n    We need to find matchups where matchupPeriodId == requested_week and check if they have scores.\n    \"\"\"\n    if not boxscore_data:\n        return False\n\n    schedule = boxscore_data.get('schedule', [])\n    if not schedule:\n        return False\n\n    # Find matchups for the requested week\n    week_matchups = [m for m in schedule if m.get('matchupPeriodId') == requested_week]\n\n    if not week_matchups:\n        # No matchups found for this week (week doesn't exist)\n        return False\n\n    # Check if any matchup for this week has actual scores\n    for matchup in week_matchups:\n        home_score = matchup.get('home', {}).get('totalPoints', 0)\n        away_score = matchup.get('away', {}).get('totalPoints', 0)\n\n        # If any team has scored points, the week has been played\n        if home_score > 0 or away_score > 0:\n            return True\n\n    # All matchups for this week have 0 scores\n    return False\n\n\ndef scrape_league(league_id: int, years: list[int], week: Optional[int], output_dir: str) -> None:\n    \"\"\"Scrape ESPN Fantasy Football data for the given parameters.\"\"\"\n    # Get ESPN authentication credentials from environment variables (for private leagues)\n    espn_s2 = os.getenv('ESPN_S2')\n    swid = os.getenv('SWID')\n\n    if espn_s2 and swid:\n        logging.info(\"Using ESPN authentication credentials for private league access\")\n    else:\n        logging.info(\"No authentication credentials found - accessing public league only\")\n\n    # Clear existing CSV files to start fresh\n    clear_existing_csv_files(output_dir)\n\n    csv_generator = CSVGenerator(output_dir)\n\n    # Determine weeks to process\n    weeks = [week] if week else range(1, MAX_WEEK + 1)\n\n    # Loop through each year\n    for year in years:\n        logging.info(f\"Processing season {year}...\")\n\n        # Initialize API for this year with optional authentication\n        api = ESPNFantasyAPI(league_id, year, espn_s2=espn_s2, swid=swid)\n\n        # Validate league\n        if not api.validate_league():\n            logging.error(f\"Invalid or inaccessible league ID: {league_id} for season {year}\")\n            continue\n\n        # Get league data\n        league_data = api.get_league_data()\n        if not league_data:\n            logging.error(f\"Failed to fetch league data for season {year}\")\n            continue\n\n        data_processor = DataProcessor(league_data)\n\n        # Process each week for this year\n        for week_number in weeks:\n            logging.info(f\"Processing {year} week {week_number}...\")\n\n            # Fetch boxscore data\n            boxscore_data = api.get_boxscore(week_number)\n            if not boxscore_data:\n                logging.warning(f\"Skipping {year} week {week_number} - no data available\")\n                continue\n\n            # Check if the week has been played (matchupPeriodId matches requested week)\n            if not has_week_been_played(boxscore_data, week_number):\n                logging.info(f\"Skipping {year} week {week_number} - no games played yet\")\n                continue\n\n            try:\n                # Process data\n                matchups_df = data_processor.process_matchups(boxscore_data, week_number)\n                player_stats_df = data_processor.process_player_stats(boxscore_data, week_number)\n                team_stats_df = data_processor.process_team_stats(boxscore_data, week_number)\n\n                # Add season column to track which year the data is from\n                matchups_df['season'] = year\n                player_stats_df['season'] = year\n                team_stats_df['season'] = year\n\n                # Save to CSV\n                csv_generator.append_to_csv(matchups_df, OUTPUT_FILES['matchups'])\n                csv_generator.append_to_csv(player_stats_df, OUTPUT_FILES['player_stats'])\n                csv_generator.append_to_csv(team_stats_df, OUTPUT_FILES['team_stats'])\n\n                logging.info(f\"Successfully processed {year} week {week_number}\")\n\n            except Exception as exc:\n                logging.error(f\"Error processing {year} week {week_number}: {exc}\")\n                continue\n\n    logging.info(\"Data scraping completed successfully\")\n\n\ndef main():\n    \"\"\"Main execution function.\"\"\"\n    setup_logging()\n    args = parse_arguments()\n\n    if not validate_arguments(args):\n        sys.exit(1)\n\n    scrape_league(\n        league_id=args.league_id,\n        years=args.years,\n        week=args.week,\n        output_dir=args.output\n    )\n\n\nif __name__ == \"__main__\":\n    main()\n","path":null,"size_bytes":6987,"size_tokens":null},"src/__init__.py":{"content":"\"\"\"Skattebot source package.\"\"\"\n","path":null,"size_bytes":32,"size_tokens":null},"src/scraper/csv_generator.py":{"content":"\"\"\"Generate CSV files from processed fantasy football data.\"\"\"\nimport os\nimport logging\nfrom typing import Dict\n\nimport pandas as pd\n\n\nclass CSVGenerator:\n    def __init__(self, output_dir: str = \".\"):\n        self.output_dir = output_dir\n        self._ensure_output_dir()\n\n    def _ensure_output_dir(self):\n        \"\"\"Ensure output directory exists.\"\"\"\n        try:\n            if not os.path.exists(self.output_dir):\n                os.makedirs(self.output_dir)\n        except OSError as e:\n            logging.error(f\"Failed to create output directory: {e}\")\n            raise\n\n    def save_dataframe(self, df: pd.DataFrame, filename: str):\n        \"\"\"Save DataFrame to CSV file.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n            df.to_csv(output_path, index=False)\n            logging.info(f\"Successfully saved {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to save {filename}: {e}\")\n            raise\n\n    def append_to_csv(self, df: pd.DataFrame, filename: str):\n        \"\"\"Append DataFrame to existing CSV file or create new one.\"\"\"\n        try:\n            output_path = os.path.join(self.output_dir, filename)\n\n            if os.path.exists(output_path):\n                df.to_csv(output_path, mode='a', header=False, index=False)\n            else:\n                df.to_csv(output_path, index=False)\n\n            logging.info(f\"Successfully appended to {filename}\")\n        except Exception as e:\n            logging.error(f\"Failed to append to {filename}: {e}\")\n            raise\n","path":null,"size_bytes":1567,"size_tokens":null},"src/analysis/team_analysis.py":{"content":"#!/usr/bin/env python3\n\"\"\"\nESPN Fantasy Football Team Statistics Analysis\nGenerates summary tables, markdown reports, and visualizations including WAX (Wins Above Expectation).\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport os\nfrom pathlib import Path\nfrom typing import Iterable\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.facecolor'] = 'white'\nplt.rcParams['axes.facecolor'] = 'white'\n\nDEFAULT_TEAM_STATS = \"team_stats.csv\"\nDEFAULT_REPORT_DIR = \".\"\nVISUALIZATIONS_SUBDIR = \"visualizations\"\n\n\ndef _ensure_dir(path: Path) -> Path:\n    path.mkdir(parents=True, exist_ok=True)\n    return path\n\n\ndef load_data(filename: str | Path = DEFAULT_TEAM_STATS) -> pd.DataFrame:\n    \"\"\"Load team stats from CSV.\"\"\"\n    return pd.read_csv(Path(filename))\n\n\ndef calculate_summary_stats(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"Calculate season summary statistics including WAX.\"\"\"\n    summary = df.groupby(['team_name', 'season']).agg({\n        'wins': 'sum',\n        'mvp_w': 'sum',\n        'top6_wins': 'sum',\n        'points_for': 'sum',\n        'points_against': 'sum',\n        'weekly_rank': 'mean'\n    }).reset_index()\n\n    summary['wax'] = summary['wins'] - summary['mvp_w']\n\n    weeks_played = df.groupby(['team_name', 'season']).size().reset_index(name='games_played')\n    summary = summary.merge(weeks_played, on=['team_name', 'season'])\n    summary['ppg'] = summary['points_for'] / summary['games_played']\n    summary['papg'] = summary['points_against'] / summary['games_played']\n\n    summary = summary.rename(columns={\n        'wins': 'real_wins',\n        'weekly_rank': 'avg_weekly_rank'\n    })\n\n    summary['power_score'] = (summary['real_wins'] * 2) + summary['top6_wins'] + summary['mvp_w']\n    summary['power_rank'] = summary.groupby('season')['power_score'].rank(ascending=False, method='min').astype(int)\n\n    summary['wax'] = summary['wax'].round(2)\n    summary['ppg'] = summary['ppg'].round(2)\n    summary['papg'] = summary['papg'].round(2)\n    summary['avg_weekly_rank'] = summary['avg_weekly_rank'].round(2)\n    summary['power_score'] = summary['power_score'].round(2)\n\n    summary = summary.sort_values('wax', ascending=False)\n    return summary\n\n\ndef print_summary_table(summary: pd.DataFrame) -> None:\n    \"\"\"Print formatted summary table.\"\"\"\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ESPN FANTASY FOOTBALL TEAM SUMMARY\")\n    print(\"=\" * 100)\n    print(\"\\nPOWER RANKINGS FORMULA:\")\n    print(\"  [Power Score] = (Real Wins × 2) + (Top6 Wins × 1) + (MVP-W × 1)\")\n    print(\"  This weights actual matchup wins heavily while rewarding consistent high scoring.\")\n    print(\"\\nWINS ABOVE EXPECTATION (WAX):\")\n    print(\"  [WAX] = [Real Wins] - [MVP-W]\")\n    print(\"  MVP-W represents theoretical wins if playing all teams every week.\")\n    print(\"  Positive WAX = lucky (running hot), Negative WAX = unlucky (running cold).\")\n    print(\"=\" * 100)\n    print()\n\n    display_cols = ['team_name', 'season', 'power_rank', 'power_score', 'real_wins',\n                    'top6_wins', 'mvp_w', 'wax', 'ppg', 'games_played']\n    display_df = summary[display_cols].copy()\n    display_df.columns = ['Team', 'Season', 'Rank', 'Power', 'Wins', 'Top6',\n                          'MVP-W', 'WAX', 'PPG', 'GP']\n\n    print(display_df.to_string(index=False))\n    print(\"\\n\" + \"=\" * 100)\n    print(f\"Total Teams: {len(display_df)}\")\n    print(\"=\" * 100 + \"\\n\")\n\n\ndef _viz_colors(length: int) -> Iterable:\n    return plt.cm.get_cmap('RdYlGn')(np.linspace(0.3, 0.9, length))\n\n\ndef create_visualizations(df: pd.DataFrame, summary: pd.DataFrame, output_dir: str | Path = VISUALIZATIONS_SUBDIR) -> None:\n    \"\"\"Create comprehensive visualizations.\"\"\"\n    output_dir = _ensure_dir(Path(output_dir))\n    latest_season = df['season'].max()\n    current_summary = summary[summary['season'] == latest_season].copy()\n\n    def _save(fig, path: Path, message: str):\n        fig.tight_layout()\n        fig.savefig(path, dpi=300, bbox_inches='tight')\n        print(f\"✓ Created: {path.as_posix()} - {message}\")\n        plt.close(fig)\n\n    # Figure 0: Power Rankings\n    fig, ax = plt.subplots(figsize=(12, 9))\n    power_sorted = current_summary.sort_values('power_score', ascending=True)\n    colors_power = _viz_colors(len(power_sorted))[::-1]\n    bars = ax.barh(power_sorted['team_name'], power_sorted['power_score'],\n                   color=colors_power, alpha=0.85, edgecolor='black', linewidth=1.5)\n    ax.set_xlabel('Power Score', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Rankings - {latest_season} Season\\nFormula: (Wins × 2) + (Top6 Wins) + (MVP-W)',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar, (_, row) in zip(bars, power_sorted.iterrows()):\n        width = bar.get_width()\n        ax.text(width + 0.3, bar.get_y() + bar.get_height() / 2,\n                f'{width:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n        ax.text(0.5, bar.get_y() + bar.get_height() / 2,\n                f'#{int(row[\"power_rank\"])}', ha='left', va='center', fontweight='bold', fontsize=11,\n                color='white', bbox=dict(boxstyle='round,pad=0.3', facecolor='black', alpha=0.7))\n    _save(fig, output_dir / 'power_rankings.png', 'Overall power rankings')\n\n    # Figure 1: WAX Leaderboard\n    fig, ax = plt.subplots(figsize=(12, 8))\n    colors = ['#2ecc71' if x > 0 else '#e74c3c' for x in current_summary['wax']]\n    bars = ax.barh(current_summary['team_name'], current_summary['wax'], color=colors, alpha=0.8)\n    ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n    ax.set_xlabel('WAX (Wins Above Expectation)', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Fantasy Football Luck Index - {latest_season} Season\\nWAX = Real Wins - MVP-W',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar, val in zip(bars, current_summary['wax']):\n        label = f'{val:+.2f}'\n        x_pos = val + (0.1 if val > 0 else -0.1)\n        ha = 'left' if val > 0 else 'right'\n        ax.text(x_pos, bar.get_y() + bar.get_height() / 2, label,\n                ha=ha, va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'wax_leaderboard.png', 'Luck index (WAX) leaderboard')\n\n    # Figure 2: Real Wins vs MVP-W Scatter\n    fig, ax = plt.subplots(figsize=(10, 10))\n    scatter = ax.scatter(current_summary['mvp_w'], current_summary['real_wins'],\n                         s=200, c=current_summary['wax'], cmap='RdYlGn',\n                         alpha=0.8, edgecolors='black', linewidth=1.5)\n    min_val = min(current_summary['mvp_w'].min(), current_summary['real_wins'].min())\n    max_val = max(current_summary['mvp_w'].max(), current_summary['real_wins'].max())\n    ax.plot([min_val, max_val], [min_val, max_val], 'k--', alpha=0.5, linewidth=2,\n            label='Expected (No Luck)')\n    for _, row in current_summary.iterrows():\n        ax.annotate(row['team_name'], (row['mvp_w'], row['real_wins']),\n                    xytext=(5, 5), textcoords='offset points', fontsize=9, fontweight='bold')\n    ax.set_xlabel('MVP-W (Expected Wins)', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Real Wins', fontsize=12, fontweight='bold')\n    ax.set_title(f'Luck Analysis: Real Wins vs Expected Wins - {latest_season}\\nAbove Line = Lucky, Below Line = Unlucky',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3)\n    ax.legend(loc='upper left', fontsize=11)\n    cbar = plt.colorbar(scatter, ax=ax)\n    cbar.set_label('WAX', rotation=270, labelpad=20, fontweight='bold', fontsize=11)\n    _save(fig, output_dir / 'wins_vs_expected.png', 'Real wins vs expected wins')\n\n    # Figure 3: Total Points Scored\n    fig, ax = plt.subplots(figsize=(12, 8))\n    sorted_summary = current_summary.sort_values('points_for', ascending=True)\n    colors_pf = _viz_colors(len(sorted_summary))\n    bars = ax.barh(sorted_summary['team_name'], sorted_summary['points_for'],\n                   color=colors_pf, alpha=0.8)\n    ax.set_xlabel('Total Points For', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Total Points Scored - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar in bars:\n        width = bar.get_width()\n        ax.text(width - 30, bar.get_y() + bar.get_height() / 2,\n                f'{width:.1f}', ha='right', va='center', fontweight='bold', fontsize=10, color='white')\n    _save(fig, output_dir / 'total_points.png', 'Total points scored')\n\n    # Figure 4: Power Score Breakdown (Stacked Bar)\n    fig, ax = plt.subplots(figsize=(12, 9))\n    breakdown_sorted = current_summary.sort_values('power_score', ascending=True)\n    wins_component = breakdown_sorted['real_wins'] * 2\n    top6_component = breakdown_sorted['top6_wins']\n    mvp_component = breakdown_sorted['mvp_w']\n    y_pos = np.arange(len(breakdown_sorted))\n    ax.barh(y_pos, wins_component, label='Real Wins (×2)', color='#2ecc71', alpha=0.9)\n    ax.barh(y_pos, top6_component, left=wins_component, label='Top6 Wins', color='#3498db', alpha=0.9)\n    ax.barh(y_pos, mvp_component, left=wins_component + top6_component,\n            label='MVP-W', color='#9b59b6', alpha=0.9)\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(breakdown_sorted['team_name'])\n    ax.set_xlabel('Power Score Components', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Score Breakdown - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.legend(loc='lower right', fontsize=10, framealpha=0.9)\n    ax.grid(axis='x', alpha=0.3)\n    for i, (_, row) in enumerate(breakdown_sorted.iterrows()):\n        total = row['power_score']\n        ax.text(total + 0.3, i, f'{total:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'power_breakdown.png', 'Power score components')\n\n    # Figure 5: Weekly Performance Over Time\n    fig, ax = plt.subplots(figsize=(14, 8))\n    current_df = df[df['season'] == latest_season].copy()\n    for team in current_df['team_name'].unique():\n        team_data = current_df[current_df['team_name'] == team].sort_values('week')\n        ax.plot(team_data['week'], team_data['points_for'], marker='o', linewidth=2, markersize=6,\n                label=team, alpha=0.7)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Points Scored', fontsize=12, fontweight='bold')\n    ax.set_title(f'Weekly Points Scored - {latest_season} Season', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3)\n    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n    _save(fig, output_dir / 'weekly_performance.png', 'Weekly scoring trends')\n\n    # Figure 6: Weekly Rank Heatmap\n    fig, ax = plt.subplots(figsize=(14, 10))\n    pivot_data = current_df.pivot(index='team_name', columns='week', values='weekly_rank').sort_index()\n    sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn_r', cbar_kws={'label': 'Weekly Rank'},\n                linewidths=0.5, vmin=1, vmax=12, ax=ax, center=6.5)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Weekly Rank Heatmap - {latest_season} Season\\n(1 = Best, 12 = Worst)',\n                 fontsize=14, fontweight='bold', pad=20)\n    _save(fig, output_dir / 'weekly_rank_heatmap.png', 'Weekly rank heatmap')\n\n    # Figure 7: Consistency Analysis\n    fig, ax = plt.subplots(figsize=(12, 8))\n    consistency = current_df.groupby('team_name').agg({\n        'weekly_rank': 'std',\n        'points_for': 'std'\n    }).reset_index()\n    consistency.columns = ['team_name', 'rank_std', 'points_std']\n    consistency = consistency.sort_values('rank_std', ascending=True)\n    colors_cons = ['#3498db' if x < consistency['rank_std'].median() else '#e67e22'\n                   for x in consistency['rank_std']]\n    bars = ax.barh(consistency['team_name'], consistency['rank_std'], color=colors_cons, alpha=0.8)\n    ax.set_xlabel('Standard Deviation of Weekly Rank', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Team', fontsize=12, fontweight='bold')\n    ax.set_title(f'Team Consistency - {latest_season} Season\\n(Lower = More Consistent)',\n                 fontsize=14, fontweight='bold', pad=20)\n    ax.grid(axis='x', alpha=0.3)\n    for bar in bars:\n        width = bar.get_width()\n        ax.text(width + 0.1, bar.get_y() + bar.get_height() / 2,\n                f'{width:.2f}', ha='left', va='center', fontweight='bold', fontsize=10)\n    _save(fig, output_dir / 'consistency.png', 'Consistency leaderboard')\n\n    # Figure 8: Power Rankings Evolution by Week\n    fig, ax = plt.subplots(figsize=(14, 9))\n    season_df = df[df['season'] == latest_season].copy()\n    weekly_data = []\n    for week in sorted(season_df['week'].unique()):\n        week_df = season_df[season_df['week'] <= week].copy()\n        week_summary = week_df.groupby('team_name').agg({\n            'wins': 'sum',\n            'mvp_w': 'sum',\n            'top6_wins': 'sum'\n        }).reset_index()\n        week_summary['power_score'] = (week_summary['wins'] * 2) + week_summary['top6_wins'] + week_summary['mvp_w']\n        week_summary['power_rank'] = week_summary['power_score'].rank(ascending=False, method='min').astype(int)\n        week_summary['week'] = week\n        weekly_data.append(week_summary)\n    weekly_rankings = pd.concat(weekly_data, ignore_index=True)\n    teams = sorted(current_summary['team_name'].unique())\n    cmap = plt.get_cmap('tab20')\n    colors = cmap(np.linspace(0, 1, len(teams)))\n    for team, color in zip(teams, colors):\n        team_data = weekly_rankings[weekly_rankings['team_name'] == team].sort_values('week')\n        ax.plot(team_data['week'], team_data['power_score'], linewidth=2.5, label=team, color=color, alpha=0.8)\n    ax.set_xlabel('Week', fontsize=12, fontweight='bold')\n    ax.set_ylabel('Cumulative Power Score', fontsize=12, fontweight='bold')\n    ax.set_title(f'Power Score Evolution - {latest_season} Season\\nHigher is Better', fontsize=14, fontweight='bold', pad=20)\n    ax.grid(True, alpha=0.3, linestyle='--')\n    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=10, framealpha=0.9)\n    _save(fig, output_dir / 'power_rankings_evolution.png', 'Power score evolution')\n\n\ndef save_summary_csv(summary: pd.DataFrame, filename: str | Path = 'team_summary.csv') -> Path:\n    \"\"\"Save summary table to CSV.\"\"\"\n    filepath = Path(filename)\n    _ensure_dir(filepath.parent or Path('.'))\n    summary.to_csv(filepath, index=False)\n    print(f\"✓ Saved summary table to: {filepath.as_posix()}\")\n    return filepath\n\n\ndef generate_markdown_analysis(summary: pd.DataFrame,\n                               filename: str | Path = 'power_rankings_analysis.md',\n                               visualization_dir: str | Path = VISUALIZATIONS_SUBDIR) -> Path:\n    \"\"\"Generate a snarky markdown analysis of the power rankings.\"\"\"\n    output_path = Path(filename)\n    _ensure_dir(output_path.parent or Path('.'))\n    visualization_dir = _ensure_dir(Path(visualization_dir))\n    visual_prefix = Path(os.path.relpath(visualization_dir, output_path.parent or Path('.'))).as_posix()\n\n    latest_season = summary['season'].max()\n    current_summary = summary[summary['season'] == latest_season].sort_values('power_rank')\n\n    def _viz(name: str) -> str:\n        return f\"{visual_prefix}/{name}\"\n\n    md = f\"\"\"# {latest_season} Fantasy Football Power Rankings Analysis\n## A Brutally Honest Assessment of Your League's Mediocrity\n\n---\n\n## Understanding the Metrics\n\nBefore we roast your teams, let's explain how we're measuring your mediocrity:\n\n### **Power Score** (The Overall Ranking)\n```\nPower Score = (Real Wins × 2) + (Top6 Wins) + (MVP-W)\n```\nThis weights actual matchup wins heavily while rewarding consistent high scoring.\n\n### **Real Wins**\nYour head-to-head record. Weighted 2× because wins matter.\n\n### **MVP-W** (Minimized Variance Potential Wins)\nYour theoretical win rate if you played every team each week.\n\n### **Top6 Wins**\nBinary metric for finishing in the top half of scorers.\n\n### **WAX** (Wins Above Expectation)\n```\nWAX = Real Wins - MVP-W\n```\nPositive = lucky. Negative = unlucky.\n\n---\n\n## Overall Power Rankings\n\n![Power Rankings]({_viz('power_rankings.png')})\n\n## Power Score Breakdown\n\n![Power Score Breakdown]({_viz('power_breakdown.png')})\n\n## Power Score Evolution Over Time\n\n![Power Score Evolution]({_viz('power_rankings_evolution.png')})\n\n*Cumulative power score by week - higher is better.*\n\n---\n\n## Team-by-Team Analysis (With the Snark You Deserve)\n\n\"\"\"\n\n    snark_templates = {\n        1: \"Congratulations, you're actually good. With {wins} wins and the highest scoring average in the league, you're not just getting lucky—you're genuinely dominating. That {wax:+.2f} WAX means you've earned almost every win.\",\n        2: \"Solidly in second place, you're doing everything right: consistent top-6 finishes, decent wins, and you're actually *slightly* unlucky ({wax:+.2f} WAX).\",\n    }\n\n    for _, row in current_summary.iterrows():\n        rank = int(row['power_rank'])\n        team = row['team_name']\n        wins = int(row['real_wins'])\n        losses = int(row['games_played'] - row['real_wins'])\n        ppg = row['ppg']\n        wax = row['wax']\n        power = row['power_score']\n        top6 = int(row['top6_wins'])\n        mvp_w = row['mvp_w']\n\n        if rank == 1:\n            analysis = snark_templates[1].format(wins=wins, wax=wax)\n        elif rank == 2:\n            analysis = snark_templates[2].format(wax=wax)\n        elif rank == 3:\n            if wax < -1.0:\n                analysis = (f\"Oh, {team}. You're scoring {ppg:.2f} PPG with {top6} top-6 finishes,\"\n                            f\" yet you're {wins}-{losses}. That {wax:+.2f} WAX is brutal.\")\n            else:\n                analysis = (f\"Legitimately good, but luck is on your side. {wax:+.2f} WAX means you've won\"\n                            f\" {abs(wax):.1f} more games than your scoring suggests.\")\n        elif rank <= 6:\n            if wax < -0.5:\n                analysis = (f\"Victim of bad luck with {wax:+.2f} WAX. {ppg:.2f} PPG and {top6} top-6 finishes\"\n                            \" should translate to more wins.\")\n            elif wax > 0.5:\n                analysis = (f\"You're getting some help from fate. {wax:+.2f} WAX means {abs(wax):.0f} gift wins.\")\n            else:\n                analysis = (f\"Solidly average. {wins}-{losses} with {ppg:.2f} PPG is exactly what you deserve.\")\n        elif rank == 7:\n            if wax > 1.5:\n                analysis = (f\"You beautiful fraud. #{rank} in power but {wins}-{losses} because of\"\n                            f\" {wax:+.2f} WAX. Schedule luck for days.\")\n            else:\n                analysis = (f\"Lower middle tier. {ppg:.2f} PPG and {wax:+.2f} WAX scream mediocrity.\")\n        elif rank <= 9:\n            if wax > 0.3:\n                analysis = (f\"Even with {wax:+.2f} WAX helping out, you're {wins}-{losses}.\"\n                            \" Imagine if you were unlucky?\")\n            else:\n                analysis = (f\"Fighting for scraps. {ppg:.2f} PPG and {wax:+.2f} WAX won't cut it.\")\n        elif rank == 10:\n            if wax > 0.5:\n                analysis = (f\"{wins} wins despite {ppg:.2f} PPG? {wax:+.2f} WAX says you're stealing victories.\")\n            else:\n                analysis = (f\"10th place with {ppg:.2f} PPG. Not unlucky—just not good enough.\")\n        elif rank == 11:\n            analysis = (f\"Second-to-last with {wins}-{losses}. {ppg:.2f} PPG and {wax:+.2f} WAX\"\n                        \" show you're getting exactly what you deserve.\")\n        else:\n            if wax < -0.5:\n                analysis = (f\"Dead last *and* unlucky ({wax:+.2f} WAX). The universe has jokes.\")\n            else:\n                analysis = (f\"Last place with {ppg:.2f} PPG. You're earning every painful loss.\")\n\n        md += f\"\"\"### #{rank} {team} - Power Score: {power:.2f}\n**Record: {wins}-{losses} | PPG: {ppg:.2f} | WAX: {wax:+.2f}**  \n**Components: Real Wins: {wins} | Top6 Wins: {top6} | MVP-W: {mvp_w:.2f}**\n\n{analysis}\n\n---\n\n\"\"\"\n\n    md += \"\"\"\n## Final Thoughts\n\nThis league has one elite team, a cluster of contenders, a few lucky frauds, and some dumpster fires bringing up the rear. May the odds be ever in your favor.\n\n---\n\n*Power Rankings Formula: (Real Wins × 2) + (Top6 Wins) + (MVP-W)*  \n*WAX (Wins Above Expectation) = Real Wins - MVP-W*\n\"\"\"\n\n    output_path.write_text(md, encoding='utf-8')\n    print(f\"✓ Generated snarky analysis: {output_path.as_posix()}\")\n    return output_path\n\n\ndef run_analysis(team_stats_path: Path, report_dir: Path) -> dict:\n    \"\"\"Execute the full analysis pipeline and return artifact paths.\"\"\"\n    report_dir = _ensure_dir(report_dir)\n    visualizations_dir = report_dir / VISUALIZATIONS_SUBDIR\n\n    df = load_data(team_stats_path)\n    summary = calculate_summary_stats(df)\n    print_summary_table(summary)\n\n    summary_csv = save_summary_csv(summary, report_dir / 'team_summary.csv')\n    markdown_path = generate_markdown_analysis(summary, report_dir / 'power_rankings_analysis.md', visualizations_dir)\n    create_visualizations(df, summary, visualizations_dir)\n\n    return {\n        'rows': len(df),\n        'seasons': df['season'].nunique(),\n        'teams': len(summary),\n        'summary_csv': summary_csv,\n        'markdown': markdown_path,\n        'visualizations_dir': visualizations_dir,\n    }\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(description='Run the ESPN Fantasy Football analysis pipeline.')\n    parser.add_argument('--team-stats', default=DEFAULT_TEAM_STATS,\n                        help='Path to team_stats.csv (default: team_stats.csv)')\n    parser.add_argument('--report-dir', default=DEFAULT_REPORT_DIR,\n                        help='Directory to write summary, markdown, and visualizations (default: current directory)')\n    return parser.parse_args()\n\n\ndef main() -> None:\n    args = parse_args()\n    stats_path = Path(args.team_stats)\n    report_dir = Path(args.report_dir)\n\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ESPN FANTASY FOOTBALL ANALYSIS\")\n    print(\"=\" * 100)\n\n    artifacts = run_analysis(stats_path, report_dir)\n\n    print(\"\\n\" + \"=\" * 100)\n    print(\"ANALYSIS COMPLETE!\")\n    print(\"=\" * 100)\n    print(\"\\nGenerated Files:\")\n    print(f\"  • {artifacts['summary_csv'].as_posix()} - Summary statistics table with Power Rankings\")\n    print(f\"  • {artifacts['markdown'].as_posix()} - Snarky written analysis with embedded images\")\n    viz_dir = artifacts['visualizations_dir'].as_posix()\n    print(f\"  • {viz_dir}/power_rankings.png - Overall power rankings\")\n    print(f\"  • {viz_dir}/power_breakdown.png - Power score component breakdown\")\n    print(f\"  • {viz_dir}/power_rankings_evolution.png - Weekly power rankings trends\")\n    print(f\"  • {viz_dir}/wax_leaderboard.png - Luck index ranking\")\n    print(f\"  • {viz_dir}/wins_vs_expected.png - Real wins vs expected wins\")\n    print(f\"  • {viz_dir}/total_points.png - Total points scored by team\")\n    print(f\"  • {viz_dir}/weekly_performance.png - Weekly scoring trends\")\n    print(f\"  • {viz_dir}/weekly_rank_heatmap.png - Weekly rankings grid\")\n    print(f\"  • {viz_dir}/consistency.png - Team consistency analysis\")\n    print(\"=\" * 100 + \"\\n\")\n\n\nif __name__ == '__main__':\n    main()\n","path":null,"size_bytes":23651,"size_tokens":null},"src/common/position_mapping.py":{"content":"\"\"\"ESPN Fantasy Football position mappings.\"\"\"\n\n# Position ID to position name mapping\nPOSITION_MAP = {\n    0: 'QB',\n    1: 'TQB',\n    2: 'RB',\n    3: 'RB/WR',\n    4: 'WR',\n    5: 'WR/TE',\n    6: 'TE',\n    7: 'OP',\n    8: 'DT',\n    9: 'DE',\n    10: 'LB',\n    11: 'DL',\n    12: 'CB',\n    13: 'S',\n    14: 'DB',\n    15: 'DP',\n    16: 'D/ST',\n    17: 'K',\n    18: 'P',\n    19: 'HC',\n    20: 'BE',\n    21: 'IR',\n    22: '',\n    23: 'RB/WR/TE',\n    24: 'ER',\n    25: 'Rookie'\n}\n\n# Lineup slot ID to slot name mapping\nLINEUP_SLOT_MAP = {\n    0: 'QB',\n    1: 'TQB',\n    2: 'RB',\n    3: 'RB/WR',\n    4: 'WR',\n    5: 'WR/TE',\n    6: 'TE',\n    7: 'OP',\n    8: 'DT',\n    9: 'DE',\n    10: 'LB',\n    11: 'DL',\n    12: 'CB',\n    13: 'S',\n    14: 'DB',\n    15: 'DP',\n    16: 'D/ST',\n    17: 'K',\n    18: 'P',\n    19: 'HC',\n    20: 'BENCH',\n    21: 'IR',\n    22: '',\n    23: 'FLEX',\n    24: 'ER',\n    25: 'Rookie'\n}\n","path":null,"size_bytes":900,"size_tokens":null},"src/scraper/espn_api.py":{"content":"\"\"\"ESPN Fantasy Football API interaction module.\"\"\"\nimport logging\nfrom typing import Any, Dict, Optional\n\nimport requests\n\nfrom src.common.config import ESPN_FF_BASE_URL\n\n\nclass ESPNFantasyAPI:\n    def __init__(self, league_id: int, season: int, espn_s2: Optional[str] = None, swid: Optional[str] = None):\n        self.league_id = league_id\n        self.season = season\n        self.base_url = ESPN_FF_BASE_URL\n        self.espn_s2 = espn_s2\n        self.swid = swid\n\n    def _get_cookies(self) -> Optional[Dict[str, str]]:\n        \"\"\"Build cookies dict for private league authentication.\"\"\"\n        if self.espn_s2 and self.swid:\n            return {\n                'espn_s2': self.espn_s2,\n                'SWID': self.swid\n            }\n        return None\n\n    def get_league_data(self) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch league data from ESPN API.\"\"\"\n        response = None\n        try:\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            cookies = self._get_cookies()\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                'Accept': 'application/json'\n            }\n            response = requests.get(url, cookies=cookies, headers=headers, timeout=30)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch league data: {e}\")\n            if response:\n                logging.error(f\"Response status: {response.status_code}\")\n            return None\n\n    def get_boxscore(self, week: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Fetch boxscore data for a specific week.\"\"\"\n        try:\n            params = {\n                'scoringPeriodId': week,\n                'view': 'mMatchup'\n            }\n            url = f\"{self.base_url}/seasons/{self.season}/segments/0/leagues/{self.league_id}\"\n            cookies = self._get_cookies()\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n                'Accept': 'application/json'\n            }\n            response = requests.get(url, params=params, cookies=cookies, headers=headers, timeout=30)\n            response.raise_for_status()\n            return response.json()\n        except requests.exceptions.RequestException as e:\n            logging.error(f\"Failed to fetch boxscore for week {week}: {e}\")\n            return None\n\n    def validate_league(self) -> bool:\n        \"\"\"Validate if the league ID exists and is accessible.\"\"\"\n        try:\n            league_data = self.get_league_data()\n            return league_data is not None and 'id' in league_data\n        except Exception:\n            return False\n","path":null,"size_bytes":2810,"size_tokens":null},"src/scraper/data_processor.py":{"content":"\"\"\"Process and transform ESPN Fantasy Football data.\"\"\"\nimport logging\nfrom typing import Any, Dict\n\nimport pandas as pd\n\nfrom src.common.position_mapping import LINEUP_SLOT_MAP, POSITION_MAP\n\n\nclass DataProcessor:\n    def __init__(self, league_data: Dict[str, Any]):\n        self.league_data = league_data\n        self.teams_map = self._create_teams_map()\n\n    def _create_teams_map(self) -> Dict[int, str]:\n        \"\"\"Create a mapping of team IDs to team names.\"\"\"\n        teams_map = {}\n        try:\n            for team in self.league_data.get('teams', []):\n                # ESPN may have different name fields - try multiple options\n                team_id = team['id']\n                team_name = (\n                    team.get('name') or\n                    f\"{team.get('location', '')} {team.get('nickname', '')}\".strip() or\n                    team.get('abbrev', f'Team {team_id}')\n                )\n                teams_map[team_id] = team_name\n        except KeyError as e:\n            logging.error(f\"Error creating teams map: {e}\")\n        return teams_map\n\n    def process_matchups(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process matchup data into a DataFrame.\"\"\"\n        matchups = []\n\n        try:\n            for matchup in boxscore_data.get('schedule', []):\n                home_team_id = matchup['home']['teamId']\n                away_team_id = matchup['away']['teamId']\n                home_score = matchup['home']['totalPoints']\n                away_score = matchup['away']['totalPoints']\n\n                matchups.extend([\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': home_team_id,\n                        'team_name': self.teams_map.get(home_team_id, f'Team {home_team_id}'),\n                        'opponent_id': away_team_id,\n                        'opponent_name': self.teams_map.get(away_team_id, f'Team {away_team_id}'),\n                        'team_score': home_score,\n                        'opponent_score': away_score,\n                        'winner': home_score > away_score\n                    },\n                    {\n                        'week': week,\n                        'matchup_id': matchup['id'],\n                        'team_id': away_team_id,\n                        'team_name': self.teams_map.get(away_team_id, f'Team {away_team_id}'),\n                        'opponent_id': home_team_id,\n                        'opponent_name': self.teams_map.get(home_team_id, f'Team {home_team_id}'),\n                        'team_score': away_score,\n                        'opponent_score': home_score,\n                        'winner': away_score > home_score\n                    }\n                ])\n        except KeyError as e:\n            logging.error(f\"Error processing matchups: {e}\")\n\n        return pd.DataFrame(matchups)\n\n    def process_player_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process player statistics into a DataFrame.\"\"\"\n        player_stats = []\n\n        try:\n            for team in boxscore_data.get('teams', []):\n                team_id = team['id']\n                team_name = self.teams_map.get(team_id, f'Team {team_id}')\n\n                for player in team.get('roster', {}).get('entries', []):\n                    position_id = player['playerPoolEntry']['player']['defaultPositionId']\n                    slot_id = player['lineupSlotId']\n\n                    player_stats.append({\n                        'week': week,\n                        'team_id': team_id,\n                        'team_name': team_name,\n                        'player_id': player['playerId'],\n                        'player_name': player['playerPoolEntry']['player']['fullName'],\n                        'position': POSITION_MAP.get(position_id, f'POS_{position_id}'),\n                        'slot_position': LINEUP_SLOT_MAP.get(slot_id, f'SLOT_{slot_id}'),\n                        'points': player['playerPoolEntry']['appliedStatTotal'],\n                        'projected_points': player['playerPoolEntry'].get('projectedPointTotal', 0)\n                    })\n        except KeyError as e:\n            logging.error(f\"Error processing player stats: {e}\")\n\n        return pd.DataFrame(player_stats)\n\n    def process_team_stats(self, boxscore_data: Dict[str, Any], week: int) -> pd.DataFrame:\n        \"\"\"Process team statistics into a DataFrame.\"\"\"\n        team_stats = []\n\n        try:\n            # Build team stats from matchup schedule data\n            team_points = {}\n            team_points_against = {}\n\n            for matchup in boxscore_data.get('schedule', []):\n                if matchup.get('matchupPeriodId') == week:\n                    home_id = matchup.get('home', {}).get('teamId')\n                    away_id = matchup.get('away', {}).get('teamId')\n                    home_points = matchup.get('home', {}).get('totalPoints', 0)\n                    away_points = matchup.get('away', {}).get('totalPoints', 0)\n\n                    if home_id and away_id:\n                        team_points[home_id] = home_points\n                        team_points[away_id] = away_points\n                        team_points_against[home_id] = away_points\n                        team_points_against[away_id] = home_points\n\n            # Sort teams by points\n            sorted_teams = sorted(team_points.items(), key=lambda x: x[1], reverse=True)\n\n            # Calculate stats for each team\n            total_teams = len(team_points)\n\n            for rank, (team_id, points) in enumerate(sorted_teams, 1):\n                points_against = team_points_against.get(team_id, 0)\n\n                # Wins: 1 if won matchup, 0 if lost\n                wins = 1 if points > points_against else 0\n\n                # Top6Wins: 1 if in top 6 scorers, 0 otherwise\n                top6_wins = 1 if rank <= 6 else 0\n\n                # mvp_w: all-play winning percentage\n                # Count how many teams this team would have beaten\n                teams_beaten = sum(1 for other_points in team_points.values() if points > other_points)\n                # Divide by number of other teams (total - 1)\n                mvp_w = teams_beaten / (total_teams - 1) if total_teams > 1 else 0\n\n                team_stats.append({\n                    'week': week,\n                    'team_id': team_id,\n                    'team_name': self.teams_map.get(team_id, f\"Team {team_id}\"),\n                    'points_for': points,\n                    'points_against': points_against,\n                    'weekly_rank': rank,\n                    'wins': wins,\n                    'top6_wins': top6_wins,\n                    'mvp_w': round(mvp_w, 4)\n                })\n        except (KeyError, TypeError) as e:\n            logging.error(f\"Error processing team stats: {e}\")\n\n        return pd.DataFrame(team_stats)\n","path":null,"size_bytes":6931,"size_tokens":null},"replit.md":{"content":"# ESPN Fantasy Football Scraper & Analyzer\n\n## Overview\nA comprehensive ESPN Fantasy Football data scraper and analysis tool that downloads historical league data and generates advanced statistical visualizations.\n\n**Current Status**: Fully functional with 2025 season data (weeks 1-10 processed)\n## Replit Deployment Guide\n\nThis document captures the Replit-specific steps for running the automated Tuesday recap workflow that now lives in `src/automation/runner.py`.\n\n## 1. Import and Boot\n1. From Replit, click **Create Repl → Import from GitHub** and select this repository.\n2. Replit installs Python 3.11 plus the system packages defined in `replit.nix` automatically.\n3. Wait for Poetry to finish pulling dependencies from `pyproject.toml` before touching the Run button.\n\n## 2. Required secrets and env vars\n\n| Key | Required | Purpose |\n| --- | --- | --- |\n| `ESPN_S2` | Private leagues only | ESPN auth cookie (long string) |\n| `SWID` | Private leagues only | ESPN auth cookie with braces |\n| `EMAIL_FROM` | Optional | From address for recap email |\n| `EMAIL_TO` | Optional | Comma-separated list of recipients |\n| `SMTP_HOST` | Optional | SMTP server used for outbound mail |\n| `SMTP_PORT` | Optional | Defaults to 587 if omitted |\n| `SMTP_USERNAME` | Optional | SMTP login |\n| `SMTP_PASSWORD` | Optional | SMTP password/app password |\n| `LEAGUE_ID` | Optional | Used by the deployment command if you prefer not to hard-code args |\n| `YEARS` | Optional | Space-delimited season list for deployments (for example `2023 2024`) |\n\nAdd these under the **Secrets** tab (lock icon). Replit exposes them as environment variables so the automation runner and `.replit` workflows can consume them without hard-coding values.\n\n## 3. Manual runs inside Replit\n\n### Run button\nThe Run button triggers the `Project` workflow described in `.replit`, which in turn executes:\n\n```\npython -m src.automation.runner --league-id 149388 --years 2024\n```\n\nUpdate the args in `.replit` or override them in the shell command below to match your league. Each run performs the full pipeline:\n\n1. Scrape ESPN data into `data/latest/`.\n2. Generate reports/visuals in `reports/latest/`.\n3. Archive the artifacts under `archive/<timestamp>/`.\n4. Email the summary CSV + markdown newsletter if SMTP + email env vars are present.\n\n### Shell access\nFor ad-hoc testing you can run commands directly:\n\n```bash\npython -m src.scraper.espn_ff_scraper --league_id 12345 --years 2024 2025 --output ./data/latest\npython -m src.analysis.team_analysis ./data/latest/team_stats.csv ./reports/latest\npython -m src.automation.runner --league-id 12345 --years 2024 2025 --verbose\n```\n\n## 4. Scheduling with Replit Deployments\n\n1. Open the **Deployments** panel and choose **Background Worker** (runs on a schedule without needing a web server).\n2. Point the deployment command to the same automation runner used in `.replit`:\n    ```\n    python -m src.automation.runner --league-id ${LEAGUE_ID} --years ${YEARS}\n    ```\n3. Define a schedule (e.g., every Tuesday at 8 AM in your time zone) using Replit's cron picker.\n4. Populate the environment variables listed in section 2 for the deployment (Deployments do not inherit secrets by default, so copy them over).\n5. Save and activate the deployment. Replit will spin up the worker on the cadence you configured.\n\n### Testing deployments\nUse the **Run Once** button inside the deployment screen to verify logs, email delivery, and archive output before trusting the schedule.\n\n## 5. Troubleshooting tips\n\n- **403 errors** almost always mean ESPN cookies are missing or expired; refresh `ESPN_S2`/`SWID`.\n- **No email delivered**: ensure `EMAIL_FROM`, `EMAIL_TO`, `SMTP_HOST`, and credentials are set. Use `--verbose` for detailed SMTP logs.\n- **Missing artifacts**: the automation runner wipes `data/latest` and `reports/latest` on each run. Pull historical data from `archive/<timestamp>/` instead.\n- **Module import errors**: confirm you are running commands with `python -m ...` from the repo root so Python can resolve the `src` package.\n\nWith the automation runner wired up, Replit can now scrape, analyze, archive, and email the weekly newsletter with a single scheduled task.\n## Key Metrics Explained\n","path":null,"size_bytes":4221,"size_tokens":null},"src/analysis/__init__.py":{"content":"\"\"\"Analytics and reporting modules for Skattebot.\"\"\"\n","path":null,"size_bytes":53,"size_tokens":null},"src/scraper/__init__.py":{"content":"\"\"\"Scraper modules for ESPN data collection.\"\"\"\n","path":null,"size_bytes":48,"size_tokens":null},"power_rankings_analysis.md":{"content":"# 2025 Fantasy Football Power Rankings Analysis\n## A Brutally Honest Assessment of Your League's Mediocrity\n\n---\n\n## Understanding the Metrics\n\nBefore we roast your teams, let's explain how we're measuring your mediocrity:\n\n### **Power Score** (The Overall Ranking)\n```\nPower Score = (Real Wins × 2) + (Top6 Wins) + (MVP-W)\n```\nThis is our ultimate measure of team quality. It heavily weights **actual matchup wins** (multiplied by 2) because winning is what matters most. But it also rewards teams that consistently score in the top half (**Top6 Wins**) and would beat multiple opponents each week (**MVP-W**). A high power score means you're legitimately good, not just lucky.\n\n### **Real Wins**\nYour actual head-to-head record. Pretty simple: did you score more than your opponent? These are the only wins that show up in the standings, which is why they're weighted 2x in the Power Score.\n\n### **MVP-W** (Minimized Variance Potential Wins)\nThis is your theoretical win rate if you played **all teams in the league every single week**. \n\n**How it's calculated:**\n- Each week, we rank all 12 teams by their scores\n- Your MVP-W for that week = (number of teams you beat) ÷ (total teams - 1)\n- Example: If you scored 4th-highest in week 1, you beat 8 teams → MVP-W = 8/11 = 0.727\n\nSum this across all weeks, and you get your season MVP-W. It measures how dominant your scoring is regardless of who you actually played. High scorers have high MVP-W; low scorers don't.\n\n### **Top6 Wins**\nBinary metric: did you finish in the **top half** of scorers that week? \n- 1 point if you ranked #1-6 \n- 0 points if you ranked #7-12\n\nSum across all weeks. This rewards consistency—teams that regularly score well get more Top6 Wins. It's harder to fluke your way into consistent top-6 finishes than it is to steal a lucky head-to-head win.\n\n### **WAX** (Wins Above Expectation) - The Luck Index\n```\nWAX = Real Wins - MVP-W\n```\nThis tells you if you're **lucky or unlucky**:\n- **Positive WAX** = You're lucky (winning more games than your scoring deserves)\n- **Negative WAX** = You're unlucky (losing games despite good scoring)\n- **WAX near 0** = You're getting exactly what you deserve\n\nExample: If you have 6 real wins but only 4.0 MVP-W, your WAX is +2.0. That means you've won 2 more games than expected based on your scoring. You're benefiting from a favorable schedule or weak opponents having bad weeks against you.\n\n---\n\n## Overall Power Rankings\n\n![Power Rankings](visualizations/power_rankings.png)\n\n## Power Score Breakdown\n\n![Power Score Breakdown](visualizations/power_breakdown.png)\n\n## Power Score Evolution Over Time\n\n![Power Score Evolution](visualizations/power_rankings_evolution.png)\n\n*Cumulative power score by week - higher is better. Watch how teams' performances build throughout the season.*\n\n---\n\n## Team-by-Team Analysis (With the Snark You Deserve)\n\n### #1 MP - Power Score: 31.73\n**Record: 8-2 | PPG: 121.44 | WAX: +0.27**  \n**Components: Real Wins: 8 | Top6 Wins: 8 | MVP-W: 7.73**\n\nCongratulations, you're actually good. With 8 wins and the highest scoring average in the league, you're not just getting lucky—you're genuinely dominating. That +0.27 WAX means you've earned almost every win. The rest of the league is basically playing for second place at this point. Enjoy your inevitable championship and the awkward silence when you try to talk about your fantasy team at parties.\n\n---\n\n### #2 sgf - Power Score: 24.18\n**Record: 6-4 | PPG: 112.89 | WAX: -0.18**  \n**Components: Real Wins: 6 | Top6 Wins: 6 | MVP-W: 6.18**\n\nSolidly in second place, you're doing everything right: consistent top-6 finishes, decent wins, and you're actually *slightly* unlucky (-0.18 WAX). You're the tortoise to MP's hare, except the hare is already at the finish line and the tortoise is stuck in traffic. Still, you're legitimately good—just not good enough to catch the leader.\n\n---\n\n### #3 GV - Power Score: 23.36\n**Record: 6-4 | PPG: 103.66 | WAX: +0.64**  \n**Components: Real Wins: 6 | Top6 Wins: 6 | MVP-W: 5.36**\n\nLegitimately good, but let's be honest—you're getting a little help from the schedule gods. That +0.64 WAX means you've won 0.6 more games than your scoring suggests. Your 103.66 PPG is solid, but sitting at 6-4 is partly luck. Keep it up, but watch out for regression.\n\n---\n\n### #3 KIRK - Power Score: 23.36\n**Record: 5-5 | PPG: 111.27 | WAX: -1.36**  \n**Components: Real Wins: 5 | Top6 Wins: 7 | MVP-W: 6.36**\n\nOh, KIRK. You poor, unfortunate soul. You're scoring 111.27 PPG, finishing in the top 6 7 times, and somehow you're sitting at 5-5. That -1.36 WAX is brutal—you should have at least 6-4 by now. You're the fantasy football equivalent of a talented actor who never gets nominated for an Oscar. Maybe next week schedule some easier opponents? Oh wait, that's not how this works.\n\n---\n\n### #5 ZSF - Power Score: 22.64\n**Record: 5-5 | PPG: 111.25 | WAX: -0.64**  \n**Components: Real Wins: 5 | Top6 Wins: 7 | MVP-W: 5.64**\n\nAnother victim of bad luck with -0.64 WAX. You're scoring 111.25 PPG with 7 top-6 finishes, but sitting at 5-5 because apparently your opponents save their best weeks for you. The fantasy football scheduling algorithm clearly has it out for you. At least you can take solace in knowing you're better than your record suggests.\n\n---\n\n### #6 PATS - Power Score: 21.55\n**Record: 5-5 | PPG: 106.40 | WAX: -0.55**  \n**Components: Real Wins: 5 | Top6 Wins: 6 | MVP-W: 5.55**\n\nAnother victim of bad luck with -0.55 WAX. You're scoring 106.40 PPG with 6 top-6 finishes, but sitting at 5-5 because apparently your opponents save their best weeks for you. The fantasy football scheduling algorithm clearly has it out for you. At least you can take solace in knowing you're better than your record suggests.\n\n---\n\n### #7 GEMP - Power Score: 19.00\n**Record: 6-4 | PPG: 100.81 | WAX: +2.00**  \n**Components: Real Wins: 6 | Top6 Wins: 3 | MVP-W: 4.00**\n\nOh, GEMP. You beautiful, lucky bastard. You're ranked #7 in power but sitting at 6-4 because you have a league-leading +2.00 WAX. That means you've won TWO more games than your mediocre 100.81 PPG deserves. You're the kid who guesses on every test question and somehow passes. Enjoy your fraudulent record while it lasts—the fantasy gods giveth, and they definitely taketh away.\n\n---\n\n### #8 POO - Power Score: 18.45\n**Record: 5-5 | PPG: 102.37 | WAX: +0.55**  \n**Components: Real Wins: 5 | Top6 Wins: 4 | MVP-W: 4.45**\n\nEven with +0.55 WAX helping you out, you're still sitting at 5-5. That 102.37 PPG isn't doing you any favors. You're winning more than you should, and you're still struggling. Imagine if you were unlucky?\n\n---\n\n### #9 ROUX - Power Score: 17.09\n**Record: 4-6 | PPG: 96.72 | WAX: -0.09**  \n**Components: Real Wins: 4 | Top6 Wins: 5 | MVP-W: 4.09**\n\nFighting for scraps with a 4-6 record. That 96.72 PPG is bottom-tier, and your -0.09 WAX shows the fantasy gods aren't helping. Consistency isn't your strong suit. Neither is winning, apparently.\n\n---\n\n### #10 KESS - Power Score: 17.09\n**Record: 5-5 | PPG: 99.78 | WAX: +0.91**  \n**Components: Real Wins: 5 | Top6 Wins: 3 | MVP-W: 4.09**\n\nYou somehow have 5 wins despite a pathetic 99.78 PPG. That +0.91 WAX means you're winning games you have no business winning. You're like the relief pitcher who keeps giving up runs but somehow gets credited with wins. The most consistent thing about you is your ability to consistently underperform while still stumbling into victories.\n\n---\n\n### #11 WOOD - Power Score: 12.36\n**Record: 3-7 | PPG: 91.84 | WAX: -0.36**  \n**Components: Real Wins: 3 | Top6 Wins: 3 | MVP-W: 3.36**\n\nSecond-to-last with 3-7. Your 91.84 PPG is brutal, and even with -0.36 WAX, you can't escape the bottom. You're not just bad—you're bad AND getting exactly what you deserve. At least you're not in last place?\n\n---\n\n### #12 3000 - Power Score: 9.18\n**Record: 2-8 | PPG: 91.15 | WAX: -1.18**  \n**Components: Real Wins: 2 | Top6 Wins: 2 | MVP-W: 3.18**\n\nDead last. Basement dweller. The league's punching bag. You're scoring 91.15 PPG (worst in the league), you have 2 wins (also worst), and you're STILL unlucky (-1.18 WAX)! You should theoretically have 3 wins, but nope, even the universe has given up on you. The good news? You can only go up from here. The bad news? That's what you said last year.\n\n---\n\n\n## Final Thoughts\n\nThis league has: one elite team (MP), a cluster of above-average teams fighting for playoff spots, a bunch of lucky frauds (looking at you, GEMP), some genuinely unlucky squads (RIP KIRK), and absolute dumpster fires bringing up the rear (3000, we're still talking about you).\n\nMay the odds be ever in your favor. Or not. Based on these power rankings, most of you need more than luck—you need a miracle.\n\n---\n\n*Power Rankings Formula: (Real Wins × 2) + (Top6 Wins) + (MVP-W)*  \n*WAX (Wins Above Expectation) = Real Wins - MVP-W*  \n*Data through Week 10, 2025 Season*\n","path":null,"size_bytes":8901,"size_tokens":null}},"version":2}